{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure Vibe Coding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:19:39.853123Z",
     "iopub.status.busy": "2025-05-04T18:19:39.852956Z",
     "iopub.status.idle": "2025-05-04T18:24:23.164575Z",
     "shell.execute_reply": "2025-05-04T18:24:23.163507Z",
     "shell.execute_reply.started": "2025-05-04T18:19:39.853106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Optional: Clean up old numpy to avoid ABI mismatch\n",
    "!pip uninstall -y numpy\n",
    "\n",
    "# ✅ Reinstall numpy first to ensure ABI compatibility\n",
    "!pip install numpy==1.26.4 --force-reinstall\n",
    "\n",
    "# ✅ Install vLLM and compatible versions\n",
    "!pip install -U transformers==4.45.2 vllm==0.6.0\n",
    "!pip install -U torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Optional but helpful:\n",
    "!pip uninstall -y pynvml\n",
    "!pip install nvidia-ml-py\n",
    "\n",
    "# For quantized model support:\n",
    "!pip install optimum auto-gptq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Optional\n",
    "import torch\n",
    "import vllm\n",
    "from vllm import SamplingParams\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model_id = \"Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\"\n",
    "model_id = \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n",
    "\n",
    "llm = vllm.LLM(\n",
    "    model_id,\n",
    "    quantization=\"awq\",\n",
    "    max_model_len=4096,\n",
    "    enable_prefix_caching=True,\n",
    "    tensor_parallel_size=torch.cuda.device_count(),\n",
    ")\n",
    "\n",
    "tokenizer = llm.get_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:26:57.538360Z",
     "iopub.status.busy": "2025-05-04T18:26:57.538011Z",
     "iopub.status.idle": "2025-05-04T18:26:57.543660Z",
     "shell.execute_reply": "2025-05-04T18:26:57.543031Z",
     "shell.execute_reply.started": "2025-05-04T18:26:57.538323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"You are an evaluator that checks student answers based on the given question and rubric.\n",
    "\n",
    "For every input, follow these steps in order:\n",
    "1. **Evaluation**: Go through each rubric item and assign marks accordingly. \n",
    "   - Enclose marks in `<marks>` tags like this: `<marks>1/2</marks>`.\n",
    "2. **Explanation**: For each rubric item, explain the reasoning behind the assigned marks.\n",
    "3. **Final Score**: Sum the individual rubric scores and provide a total, using `<score>` tags. \n",
    "   - Format: `Final score: <score>7/8</score>`\n",
    "\n",
    "Always use these three clearly labeled sections:  \n",
    "`Evaluation:`  \n",
    "`Explanation:`  \n",
    "`Final Score:`  \n",
    "\n",
    "Be objective, fair, and detailed. Do not skip any rubric.\n",
    "\n",
    "Below are examples for you to learn the format:\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "question = Find the derivative of f(x) = x³ + 3x² + 1.\n",
    "\n",
    "rubric = \"1. States the general power rule (2 points)\n",
    "2. Applies the power rule to x³ correctly (2 points)\n",
    "3. Applies the power rule to 3x² correctly (2 points)\n",
    "4. Simplifies the derivative properly (2 points)\n",
    "\n",
    "answer = f'(x) = 3x² + 6x\n",
    "\n",
    "Response:\n",
    "\n",
    "Evaluation:\n",
    "1. The student did not explicitly state the general power rule. <marks>0/2</marks>\n",
    "2. The student correctly applied the power rule to x³. <marks>2/2</marks>\n",
    "3. The student correctly applied the power rule to 3x². <marks>2/2</marks>\n",
    "4. The simplification is correct. <marks>2/2</marks>\n",
    "\n",
    "Explanation:\n",
    "1. The general rule (d/dx[xⁿ] = n·xⁿ⁻¹) was not stated, though applied correctly.\n",
    "2. d/dx[x³] = 3x², which the student wrote.\n",
    "3. d/dx[3x²] = 6x, which is also correct.\n",
    "4. There are no like terms, and the expression is simplified properly.\n",
    "\n",
    "Final Score: <score>6/8</score>\n",
    "\n",
    "**Example 2:**\n",
    "\n",
    "question = What is the capital of France?\n",
    "\n",
    "rubric = 1. Identifies the capital correctly (2 points)\n",
    "2. Provides any additional context (1 point)\n",
    "\n",
    "answer = Paris is the capital of France. It is known for the Eiffel Tower.\n",
    "\n",
    "Response:\n",
    "\n",
    "Evaluation:\n",
    "1. Correct capital is stated. <marks>2/2</marks>\n",
    "2. Additional context about Eiffel Tower is provided. <marks>1/1</marks>\n",
    "\n",
    "Explanation:\n",
    "1. Paris is indeed the capital of France.\n",
    "2. Mentioning the Eiffel Tower adds informative context about the city.\n",
    "\n",
    "Final Score: <score>3/3</score>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:26:57.545091Z",
     "iopub.status.busy": "2025-05-04T18:26:57.544483Z",
     "iopub.status.idle": "2025-05-04T18:26:57.573071Z",
     "shell.execute_reply": "2025-05-04T18:26:57.572340Z",
     "shell.execute_reply.started": "2025-05-04T18:26:57.545067Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def llm_engine(\n",
    "    list_of_messages: List[List[dict]],\n",
    "    stop_sequences: Optional[List[str]] = None,\n",
    "    start_sequence: Optional[str] = None,\n",
    "    temperature: float = 0.2,\n",
    "    max_tokens: int = 2048\n",
    ") -> List[str]:\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,\n",
    "        max_tokens=max_tokens,\n",
    "        stop=stop_sequences,\n",
    "        include_stop_str_in_output=True,\n",
    "    )\n",
    "\n",
    "    prompts = [\n",
    "        tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        for messages in list_of_messages\n",
    "    ]\n",
    "\n",
    "    if start_sequence:\n",
    "        prompts = [prompt + start_sequence for prompt in prompts]\n",
    "\n",
    "    outputs = llm.generate(prompts, sampling_params, use_tqdm=False)\n",
    "    responses = [o.outputs[0].text.strip() for o in outputs]\n",
    "\n",
    "    if start_sequence:\n",
    "        responses = [start_sequence + response for response in responses]\n",
    "\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Raw Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:26:57.574226Z",
     "iopub.status.busy": "2025-05-04T18:26:57.573978Z",
     "iopub.status.idle": "2025-05-04T18:26:57.602314Z",
     "shell.execute_reply": "2025-05-04T18:26:57.601604Z",
     "shell.execute_reply.started": "2025-05-04T18:26:57.574202Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse_evaluation_response(response: str):\n",
    "    \"\"\"\n",
    "    Extracts rubric-wise scores, explanations, and total score from the model's output.\n",
    "    Assumes the structure:\n",
    "    Evaluation:\n",
    "    1. explanation <marks>X/Y</marks>\n",
    "    2. explanation <marks>X/Y</marks>\n",
    "    ...\n",
    "    Explanation:\n",
    "    1. ...\n",
    "    2. ...\n",
    "    Final Score:\n",
    "    The final score is: <score>X/Y</score>\n",
    "    \"\"\"\n",
    "    # --- Extract rubric-wise scores with explanations ---\n",
    "    eval_section = re.search(r\"Evaluation:(.*?)(Explanation:|Final Score:)\", response, re.DOTALL)\n",
    "    explanation_section = re.search(r\"Explanation:(.*?)(Final Score:|$)\", response, re.DOTALL)\n",
    "    final_score = re.search(r\"<score>(\\d+)\\s*/\\s*(\\d+)</score>\", response)\n",
    "\n",
    "    rubric_scores = []\n",
    "    if eval_section:\n",
    "        lines = eval_section.group(1).strip().split(\"\\n\")\n",
    "        for line in lines:\n",
    "            match = re.search(r\"(.*)<marks>(\\d+)\\s*/\\s*(\\d+)</marks>\", line.strip())\n",
    "            if match:\n",
    "                rubric_text = match.group(1).strip()\n",
    "                score = int(match.group(2))\n",
    "                total = int(match.group(3))\n",
    "                rubric_scores.append((rubric_text, score, total))\n",
    "\n",
    "    explanations = []\n",
    "    if explanation_section:\n",
    "        lines = explanation_section.group(1).strip().split(\"\\n\")\n",
    "        explanations = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    total_score = None\n",
    "    if final_score:\n",
    "        total_score = (int(final_score.group(1)), int(final_score.group(2)))\n",
    "\n",
    "    return rubric_scores, explanations, total_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchwise Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:26:57.604797Z",
     "iopub.status.busy": "2025-05-04T18:26:57.604470Z",
     "iopub.status.idle": "2025-05-04T18:26:57.628106Z",
     "shell.execute_reply": "2025-05-04T18:26:57.627346Z",
     "shell.execute_reply.started": "2025-05-04T18:26:57.604769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse_batch_evaluations(responses: list[str]):\n",
    "    \"\"\"\n",
    "    Processes a list of model responses, extracting:\n",
    "    - Rubric-wise evaluations (text + marks)\n",
    "    - Explanations\n",
    "    - Final scores\n",
    "    Returns a list of dicts, one per response.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for idx, response in enumerate(responses):\n",
    "        rubric_scores, explanations, total_score = parse_evaluation_response(response)\n",
    "\n",
    "        entry = {\n",
    "            \"response_index\": idx,\n",
    "            \"rubric_scores\": rubric_scores,       # List of (rubric_text, score, total)\n",
    "            \"explanations\": explanations,         # List of explanation strings\n",
    "            \"final_score\": total_score            # Tuple (score, total) or None\n",
    "        }\n",
    "\n",
    "        results.append(entry)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to make messages for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:45:03.335959Z",
     "iopub.status.busy": "2025-05-04T18:45:03.335696Z",
     "iopub.status.idle": "2025-05-04T18:45:03.339842Z",
     "shell.execute_reply": "2025-05-04T18:45:03.339329Z",
     "shell.execute_reply.started": "2025-05-04T18:45:03.335940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_messages(question: str, answer: str, rubric: str) -> list[dict]:\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"QUESTION:\n",
    "{question}\n",
    "\n",
    "STUDENT ANSWER:\n",
    "{answer}\n",
    "\n",
    "RUBRIC:\n",
    "{rubric}\n",
    "\"\"\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:26:57.655949Z",
     "iopub.status.busy": "2025-05-04T18:26:57.655681Z",
     "iopub.status.idle": "2025-05-04T18:26:57.677369Z",
     "shell.execute_reply": "2025-05-04T18:26:57.676637Z",
     "shell.execute_reply.started": "2025-05-04T18:26:57.655926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def majority_vote_with_explanations(parsed_batch):\n",
    "    \"\"\"\n",
    "    Takes parsed batch outputs and returns majority-voted rubric scores with explanations.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: (rubric_text, voted_score, total, explanation)\n",
    "    \"\"\"\n",
    "    rubric_scores = defaultdict(list)  # i -> [(score, total)]\n",
    "    rubric_explanations = defaultdict(list)  # i -> [explanation]\n",
    "    rubric_texts = []\n",
    "\n",
    "    for entry in parsed_batch:\n",
    "        for i, (rubric_text, score, total) in enumerate(entry['rubric_scores']):\n",
    "            rubric_scores[i].append((score, total))\n",
    "            rubric_explanations[i].append(entry['explanations'][i])\n",
    "            if len(rubric_texts) <= i:\n",
    "                rubric_texts.append(rubric_text)\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(rubric_scores)):\n",
    "        # Majority vote on score\n",
    "        score_counter = Counter(rubric_scores[i])\n",
    "        (voted_score, voted_total), _ = score_counter.most_common(1)[0]\n",
    "\n",
    "        # Most common explanation\n",
    "        explanation_counter = Counter(rubric_explanations[i])\n",
    "        voted_explanation, _ = explanation_counter.most_common(1)[0]\n",
    "\n",
    "        results.append((rubric_texts[i], voted_score, voted_total, voted_explanation))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For testing Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:27:24.160263Z",
     "iopub.status.busy": "2025-05-04T18:27:24.159663Z",
     "iopub.status.idle": "2025-05-04T18:27:24.164019Z",
     "shell.execute_reply": "2025-05-04T18:27:24.163306Z",
     "shell.execute_reply.started": "2025-05-04T18:27:24.160236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question = \"A car initially at rest, achieved a speed of 60 km/h in a minute. Calculate the accelaration of the car\"\n",
    "answer = \"\"\"Given u=0m/s,t=60s\n",
    "v=60/3.6=16.67m/s\n",
    "a=0.278ms^-2\n",
    "\"\"\"\n",
    "rubric = \"\"\"1. Identifies the given informations correctly (3 points)\n",
    "2. Mentions the formula for accelaration explicitely (2 points)\n",
    "3. Uses the correct formula for accelaration (3 points)\n",
    "4. Calculates the correct accelaration(Might be in m/s or km/h).(2 points)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T13:46:01.564073Z",
     "iopub.status.busy": "2025-05-04T13:46:01.563743Z",
     "iopub.status.idle": "2025-05-04T13:46:01.568459Z",
     "shell.execute_reply": "2025-05-04T13:46:01.567841Z",
     "shell.execute_reply.started": "2025-05-04T13:46:01.564050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "0 থেকে 2π পর্যন্ত y=sinx দ্বারা আবদ্ধ মোট ক্ষেত্রফল কত?\n",
    "\"\"\"\n",
    "answer = \"\"\"\n",
    "ধরি, \n",
    "\\[\n",
    "A = \\int_{0}^{2\\pi} \\sin x \\, dx\n",
    "\\]\n",
    "\n",
    "আমরা জানি,\n",
    "\\[\n",
    "\\int \\sin x \\, dx = -\\cos x + C\n",
    "\\]\n",
    "\n",
    "অতএব,\n",
    "\\[\n",
    "A = \\left[-\\cos x\\right]_{0}^{2\\pi}\n",
    "= \\left(-\\cos 2\\pi\\right) - \\left(-\\cos 0\\right)\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= -(1) - (-1)\n",
    "= -1 + 1 = 0\n",
    "\\]\n",
    "\n",
    "সুতরাং,\n",
    "\\[\n",
    "\\boxed{ \\text{ক্ষেত্রফল} = 0 \\text{ একক} }\n",
    "\\]\n",
    "\"\"\"\n",
    "\n",
    "rubric = \"\"\"\n",
    "1. ক্ষেত্রফলের সাথে সম্পর্কিত নির্দিষ্ট ইন্টিগ্রাল চিহ্নিত করে। (4 points)\n",
    "2. ক্ষেত্রফল ইন্টিগ্রেট করার জন্য সঠিক সূত্র ব্যবহার করে। (3 points)\n",
    "3. সঠিক ক্ষেত্রফল গণনা করে। (3 points)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:19:07.306890Z",
     "iopub.status.busy": "2025-05-04T14:19:07.306400Z",
     "iopub.status.idle": "2025-05-04T14:19:07.310767Z",
     "shell.execute_reply": "2025-05-04T14:19:07.310169Z",
     "shell.execute_reply.started": "2025-05-04T14:19:07.306868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question = \"Write a short paragraph about industrial revolution\"\n",
    "\n",
    "answer = \"\"\"The Industrial Revolushion was a time of big changes in the 1800s, when things started to be made by machines insted of by hand. \n",
    "            It started in Britain and spreaded to other countries. \n",
    "            It help make new technology and factories, but also caused problem like pollution and poor working conditions.\n",
    "            It has great impact in the history of human kind. Without industrial revolution, nothing would be possible\n",
    "        \"\"\"\n",
    "\n",
    "rubric = \"\"\"\n",
    "            1.Information is historically correct and relevant. (2 points)\n",
    "    \n",
    "            2.Sentences are grammatically correct with proper spelling. (2 points)\n",
    "            \n",
    "            3.Ideas are clearly expressed and logically connected. (2 points)\n",
    "            \n",
    "            4.Content stays focused on the Industrial Revolution. (2 points)\n",
    "            \n",
    "            5.Paragraph is brief but includes key details. (2 points)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:29:31.031370Z",
     "iopub.status.busy": "2025-05-04T14:29:31.030843Z",
     "iopub.status.idle": "2025-05-04T14:29:31.034587Z",
     "shell.execute_reply": "2025-05-04T14:29:31.033875Z",
     "shell.execute_reply.started": "2025-05-04T14:29:31.031347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question = \"Who wrote Hamlet?\"\n",
    "answer = \"Kazi Nazrul Islam\"\n",
    "rubric = \"1. Provides the correct answer (2 points)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:36:15.170901Z",
     "iopub.status.busy": "2025-05-04T14:36:15.170367Z",
     "iopub.status.idle": "2025-05-04T14:36:15.175014Z",
     "shell.execute_reply": "2025-05-04T14:36:15.174368Z",
     "shell.execute_reply.started": "2025-05-04T14:36:15.170869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question = \"Write a paragraph on Sundarban in Bangla\"\n",
    "answer = \"\"\"\n",
    "    সুন্দরবন একটি সুন্দর বন যা পাহাড়ে অবস্থিত। এটি সবসময় ঠান্ডা থাকে এবং এখানে বরফ পড়ে। \n",
    "    সুন্দরবনে অনেক ফুল ফোটে এবং মানুষ সেখানে বেড়াতে যায় পাহাড় দেখতে। সুন্দরবন মূলত একটি বড় পার্কের মতো, যেখানে পশুপাখি খাঁচায় থাকে।\n",
    "\"\"\"\n",
    "rubric = \"\"\"\n",
    "    1.তথ্যগত সঠিকতা (4 points) – সুন্দরবন সম্পর্কিত সঠিক তথ্য প্রদান করা হয়েছে কি না (অবস্থান, বৈশিষ্ট্য, প্রাণী)।\n",
    "\n",
    "    2.বিষয়বস্তুর প্রাসঙ্গিকতা (2 points) – অনুচেদটি সুন্দরবন বিষয়ে কেন্দ্রভিত্তিক ও প্রাসঙ্গিক কি না।\n",
    "    \n",
    "    3.ভাষার গঠন ও ব্যাকরণ (2 points) – সঠিক ব্যাকরণ, বানান ও বাক্য গঠন রয়েছে কি না।\n",
    "    \n",
    "    4.পরিভাষার যথাযথ ব্যবহার (2 points) – পরিবেশ, বন্যপ্রাণী ও ভূগোল সম্পর্কিত সঠিক শব্দ ও পরিভাষা ব্যবহার করা হয়েছে কি না।\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:41:18.741242Z",
     "iopub.status.busy": "2025-05-04T14:41:18.740598Z",
     "iopub.status.idle": "2025-05-04T14:41:18.746903Z",
     "shell.execute_reply": "2025-05-04T14:41:18.746151Z",
     "shell.execute_reply.started": "2025-05-04T14:41:18.741212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question = \"Write a paragraph on Sundarban in Bangla\"\n",
    "answer = \"\"\"\n",
    "    সুন্দরবন বিশ্বের সর্ববৃহৎ ম্যানগ্রোভ বন, যা বাংলাদেশ ও ভারতের একটি অংশ জুড়ে বিস্তৃত। এটি রয়েল বেঙ্গল টাইগার, চিত্রা হরিণ, কুমিরসহ অনেক বিরল প্রাণীর আবাসস্থল। \n",
    "    সুন্দরবন তার জটিল নদী-নালা, খাল এবং লবণাক্ত পরিবেশের জন্য পরিচিত। \n",
    "    এটি প্রাকৃতিক দুর্যোগ থেকে উপকূলীয় এলাকাগুলোকে রক্ষা করে এবং বাংলাদেশের পরিবেশ ও জীববৈচিত্র্যের জন্য অত্যন্ত গুরুত্বপূর্ণ।\n",
    "\"\"\"\n",
    "rubric = \"\"\"\n",
    "    1.তথ্যগত সঠিকতা (4 points) – সুন্দরবন সম্পর্কিত সঠিক তথ্য প্রদান করা হয়েছে কি না (অবস্থান, বৈশিষ্ট্য, প্রাণী)।\n",
    "\n",
    "    2.বিষয়বস্তুর প্রাসঙ্গিকতা (2 points) – অনুচেদটি সুন্দরবন বিষয়ে কেন্দ্রভিত্তিক ও প্রাসঙ্গিক কি না।\n",
    "    \n",
    "    3.ভাষার গঠন ও ব্যাকরণ (2 points) – সঠিক ব্যাকরণ, বানান ও বাক্য গঠন রয়েছে কি না।\n",
    "    \n",
    "    4.পরিভাষার যথাযথ ব্যবহার (2 points) – পরিবেশ, বন্যপ্রাণী ও ভূগোল সম্পর্কিত সঠিক শব্দ ও পরিভাষা ব্যবহার করা হয়েছে কি না।\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:27:31.316925Z",
     "iopub.status.busy": "2025-05-04T18:27:31.316583Z",
     "iopub.status.idle": "2025-05-04T18:27:58.416678Z",
     "shell.execute_reply": "2025-05-04T18:27:58.416015Z",
     "shell.execute_reply.started": "2025-05-04T18:27:31.316902Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The student correctly identifies the given information: initial velocity (u=0 m/s), time (t=60 s), and final velocity (v=16.67 m/s).. Score => 3/3\n",
      "\n",
      "2. The student does not explicitly mention the formula for acceleration.. Score => 0/2\n",
      "\n",
      "3. The student uses the correct formula for acceleration, which is \\( a = \\frac{v - u}{t} \\).. Score => 3/3\n",
      "\n",
      "4. The student calculates the correct acceleration: \\( a = \\frac{16.67 \\, \\text{m/s} - 0 \\, \\text{m/s}}{60 \\, \\text{s}} = 0.278 \\, \\text{m/s}^2 \\).. Score => 2/2\n",
      "\n",
      "\n",
      "Final Score according to majority voting: 8/10\n"
     ]
    }
   ],
   "source": [
    "# question = \"Find the derivative of f(x) = x³ + 3x² + 1.\"\n",
    "# answer = \"f'(x) = 3x² + 6x.\"\n",
    "# rubric = \"\"\"1. States the general power rule (d/dx[xⁿ]=n·xⁿ⁻¹) (2 points)\n",
    "# 2. Applies the power rule correctly to x³ (2 points)\n",
    "# 3. Applies the power rule correctly to 3x² (2 points)\n",
    "# 4. Simplifies and combines like terms properly (2 points)\"\"\"\n",
    "\n",
    "messages_batch = [make_messages(question, answer, rubric)] * 10  # for 5 voting samplesScreenshot from 2025-05-03 17-05-41\n",
    "\n",
    "responses = llm_engine(messages_batch)\n",
    "parsed_results = parse_batch_evaluations(responses)\n",
    "# majority_scores,majority_explanations,totals = majority_scores_per_rubric(parsed_results)\n",
    "results = majority_vote_with_explanations(parsed_results)\n",
    "total_mark = 0\n",
    "\n",
    "# for result in parsed_results:\n",
    "#     print(f\"\\n🔎 Response #{result['response_index'] + 1}\")\n",
    "\n",
    "#     marks_got = 0\n",
    "#     total_marks = 0\n",
    "#     for i, ((rubric, score, total), explanation) in enumerate(zip(result[\"rubric_scores\"], result[\"explanations\"]), 1):\n",
    "#         marks_got += score\n",
    "#         total_marks += total\n",
    "#         print(f\"{i}. {rubric} => Score: {score}/{total}\")\n",
    "#         print(f\"   Explanation: {explanation}\")\n",
    "    \n",
    "#     if result[\"final_score\"]:\n",
    "#         print(f\"\\n✅ Final Score: {result['final_score'][0]}/{result['final_score'][1]}\")\n",
    "#     total_mark = total_marks\n",
    "#     print(f\"\\nSummed Final Score: {marks_got}/{total_marks}\\n\")\n",
    "\n",
    "majority_scores = []\n",
    "for rubric_text, score, total, explanation in results:\n",
    "    majority_scores.append(score)\n",
    "    total_mark += total\n",
    "    print(f\"{rubric_text}. Score => {score}/{total}\")\n",
    "    # print(f\"Explanation: {explanation}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f\"\\nFinal Score according to majority voting: {sum(majority_scores)}/{total_mark}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell prints the raw responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# question = \"Find the derivative of f(x) = x³ + 3x² + 1.\"\n",
    "# answer = \"f'(x) = 3x² + 6x.\"\n",
    "# rubric = \"\"\"1. States the general power rule (d/dx[xⁿ]=n·xⁿ⁻¹) (2 points)\n",
    "# 2. Applies the power rule correctly to x³ (2 points)\n",
    "# 3. Applies the power rule correctly to 3x² (2 points)\n",
    "# 4. Writes the final result properly(no need to write 0 in the final result) (2 points)\"\"\"\n",
    "\n",
    "messages_batch = [make_messages(question, answer, rubric)] * 5  # for 5 voting samples\n",
    "\n",
    "responses = llm_engine(messages_batch)\n",
    "\n",
    "for response in responses:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Multiple questions at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:44:17.739654Z",
     "iopub.status.busy": "2025-05-04T18:44:17.738892Z",
     "iopub.status.idle": "2025-05-04T18:44:17.746711Z",
     "shell.execute_reply": "2025-05-04T18:44:17.745956Z",
     "shell.execute_reply.started": "2025-05-04T18:44:17.739627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "questions_answers_list = [\n",
    "    {\n",
    "        \"question\" : \"\"\"\n",
    "        0 থেকে π পর্যন্ত y=sinx দ্বারা আবদ্ধ ক্ষেত্রফল কত?\n",
    "        \"\"\",\n",
    "        \"answer\" : \"\"\"\n",
    "        ধরি, \n",
    "        \\[\n",
    "        A = \\int_{0}^{\\pi} \\sin x \\, dx\n",
    "        \\]\n",
    "        \n",
    "        আমরা জানি,\n",
    "        \\[\n",
    "        \\int \\sin x \\, dx = -\\cos x + C\n",
    "        \\]\n",
    "        \n",
    "        অতএব,\n",
    "        \\[\n",
    "        A = \\left[-\\cos x\\right]_{0}^{\\pi}\n",
    "        = \\left(-\\cos \\pi\\right) - \\left(-\\cos 0\\right)\n",
    "        \\]\n",
    "    \n",
    "        \\[\n",
    "        = -(-1) - (-1)\n",
    "        = 1 + 1 = 2\n",
    "        \\]\n",
    "        \n",
    "        সুতরাং,\n",
    "        \\[\n",
    "        \\boxed{ \\text{ক্ষেত্রফল} = 2 \\text{ একক} }\n",
    "        \\]\n",
    "        \"\"\",\n",
    "    \n",
    "        \"rubric\" : \"\"\"\n",
    "        1. ক্ষেত্রফলের সাথে সম্পর্কিত নির্দিষ্ট ইন্টিগ্রাল চিহ্নিত করে। (4 points)\n",
    "        2. ক্ষেত্রফল ইন্টিগ্রেট করার জন্য সঠিক সূত্র ব্যবহার করে। (3 points)\n",
    "        3. সঠিক ক্ষেত্রফল গণনা করে। (3 points)\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\" : \"A car initially at rest, achieved a speed of 60 km/h in a minute. Calculate the accelaration of the car\",\n",
    "        \"answer\" : \"\"\"Given u=0m/s,t=60s\n",
    "        v=60/3.6=16.67m/s\n",
    "        a=0.278ms^-2\n",
    "        \"\"\",\n",
    "        \"rubric\" : \"\"\"1. Identifies the given informations correctly (3 points)\n",
    "        2. Mentions the formula for accelaration explicitely (2 points)\n",
    "        3. Uses the correct formula for accelaration (3 points)\n",
    "        4. Calculates the correct accelaration(Might be in m/s or km/h).(2 points)\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\" : \"\"\"The time period of a simple pendulum in earth is 2 seconds. What will be its time period\n",
    "        in space?\n",
    "        \"\"\",\n",
    "        \"answer\" : \"The time period will be unchanged. It will still be 2 seconds\",\n",
    "        \"rubric\" : \"1. Provides the correct answer (2 points)\"\n",
    "    },\n",
    "    {\n",
    "        \"question\" : \"\"\"\n",
    "            0 থেকে 2π পর্যন্ত y=sinx দ্বারা আবদ্ধ মোট ক্ষেত্রফল কত?\n",
    "            \"\"\",\n",
    "        \"answer\" : \"\"\"\n",
    "            ধরি, \n",
    "            \\[\n",
    "            A = \\int_{0}^{2\\pi} \\sin x \\, dx\n",
    "            \\]\n",
    "            \n",
    "            আমরা জানি,\n",
    "            \\[\n",
    "            \\int \\sin x \\, dx = -\\cos x + C\n",
    "            \\]\n",
    "            \n",
    "            অতএব,\n",
    "            \\[\n",
    "            A = \\left[-\\cos x\\right]_{0}^{2\\pi}\n",
    "            = \\left(-\\cos 2\\pi\\right) - \\left(-\\cos 0\\right)\n",
    "            \\]\n",
    "            \n",
    "            \\[\n",
    "            = -(1) - (-1)\n",
    "            = -1 + 1 = 0\n",
    "            \\]\n",
    "            \n",
    "            সুতরাং,\n",
    "            \\[\n",
    "            \\boxed{ \\text{ক্ষেত্রফল} = 0 \\text{ একক} }\n",
    "            \\]\n",
    "            \"\"\",\n",
    "\n",
    "        \"rubric\" : \"\"\"\n",
    "        1. ক্ষেত্রফলের সাথে সম্পর্কিত নির্দিষ্ট ইন্টিগ্রাল চিহ্নিত করে। (4 points)\n",
    "        2. ক্ষেত্রফল ইন্টিগ্রেট করার জন্য সঠিক সূত্র ব্যবহার করে। (3 points)\n",
    "        3. সঠিক ক্ষেত্রফল গণনা করে। (3 points)\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\" : \"Write a short paragraph about industrial revolution\",\n",
    "        \"answer\":\"\"\"The Industrial Revolushion was a time of big changes in the 1800s, when things started to be made by machines insted of by hand. \n",
    "            It started in Britain and spreaded to other countries. \n",
    "            It help make new technology and factories, but also caused problem like pollution and poor working conditions.\n",
    "            It has great impact in the history of human kind. Without industrial revolution, nothing would be possible.\n",
    "        \"\"\",\n",
    "        \"rubric\":\"\"\"\n",
    "            1.Information is historically correct and relevant. (2 points)\n",
    "    \n",
    "            2.Sentences are grammatically correct with proper spelling. (2 points)\n",
    "            \n",
    "            3.Ideas are clearly expressed and logically connected. (2 points)\n",
    "            \n",
    "            4.Content stays focused on the Industrial Revolution. (2 points)\n",
    "            \n",
    "            5.Paragraph is brief but includes key details. (2 points)\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\" : \"Why benzene is stable despite having $\\pi$ bonds?\",\n",
    "        \"answer\" : \"\"\"\n",
    "            Benzene is stable because its π bonds are stronger than normal double bonds and are fixed between alternating carbon atoms. \n",
    "            The structure doesn't change because the double bonds stay in place, and this makes it stable. \n",
    "            Also, since it’s a ring, the shape helps it be more balanced and less reactive.\n",
    "        \"\"\",\n",
    "        \"rubric\": \"\"\"\n",
    "            1.Explains correct reasons (e.g., resonance, delocalization, aromaticity, Huckel's rule). (5 points)\n",
    "\n",
    "            2.Shows understanding of electron delocalization and bond behavior in benzene. (3 points)\n",
    "            \n",
    "            3.Uses correct scientific terms appropriately (e.g., π bonds, resonance, aromaticity). (2 points)\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\" : \"Write a paragraph on Sundarban in Bangla\",\n",
    "        \"answer\" : \"\"\"\n",
    "            সুন্দরবন বিশ্বের সর্ববৃহৎ ম্যানগ্রোভ বন, যা বাংলাদেশ ও ভারতের একটি অংশ জুড়ে বিস্তৃত। এটি রয়েল বেঙ্গল টাইগার, চিত্রা হরিণ, কুমিরসহ অনেক বিরল প্রাণীর আবাসস্থল। \n",
    "            সুন্দরবন তার জটিল নদী-নালা, খাল এবং লবণাক্ত পরিবেশের জন্য পরিচিত। \n",
    "            এটি প্রাকৃতিক দুর্যোগ থেকে উপকূলীয় এলাকাগুলোকে রক্ষা করে এবং বাংলাদেশের পরিবেশ ও জীববৈচিত্র্যের জন্য অত্যন্ত গুরুত্বপূর্ণ।\n",
    "        \"\"\",\n",
    "        \"rubric\" : \"\"\"\n",
    "            1.তথ্যগত সঠিকতা (4 points) – সুন্দরবন সম্পর্কিত সঠিক তথ্য প্রদান করা হয়েছে কি না (অবস্থান, বৈশিষ্ট্য, প্রাণী)।\n",
    "        \n",
    "            2.বিষয়বস্তুর প্রাসঙ্গিকতা (2 points) – অনুচেদটি সুন্দরবন বিষয়ে কেন্দ্রভিত্তিক ও প্রাসঙ্গিক কি না।\n",
    "            \n",
    "            3.ভাষার গঠন ও ব্যাকরণ (2 points) – সঠিক ব্যাকরণ, বানান ও বাক্য গঠন রয়েছে কি না।\n",
    "            \n",
    "            4.পরিভাষার যথাযথ ব্যবহার (2 points) – পরিবেশ, বন্যপ্রাণী ও ভূগোল সম্পর্কিত সঠিক শব্দ ও পরিভাষা ব্যবহার করা হয়েছে কি না।\n",
    "        \"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:46:25.082596Z",
     "iopub.status.busy": "2025-05-04T14:46:25.082324Z",
     "iopub.status.idle": "2025-05-04T14:46:25.086699Z",
     "shell.execute_reply": "2025-05-04T14:46:25.086160Z",
     "shell.execute_reply.started": "2025-05-04T14:46:25.082576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages_batches = []\n",
    "for qa in questions_answers_list: # This list is a list of dictionaries(for now)\n",
    "    question, answer, rubric = qa[\"question\"], qa[\"answer\"], qa[\"rubric\"]\n",
    "    single_message = make_messages(question, answer, rubric)\n",
    "    batch = [single_message] * 5  # 5 copies per question\n",
    "    messages_batches.extend(batch)  # flatten for vllm batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:40:12.166469Z",
     "iopub.status.busy": "2025-05-04T18:40:12.165923Z",
     "iopub.status.idle": "2025-05-04T18:40:12.170776Z",
     "shell.execute_reply": "2025-05-04T18:40:12.170125Z",
     "shell.execute_reply.started": "2025-05-04T18:40:12.166443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def batch_messages_together(questions_answers_list):\n",
    "    messages_batches = []\n",
    "    for qa in questions_answers_list: # This list is a list of dictionaries(for now)\n",
    "        question, answer, rubric = qa[\"question\"], qa[\"answer\"], qa[\"rubric\"]\n",
    "        single_message = make_messages(question, answer, rubric)\n",
    "        batch = [single_message] * 5  # 5 copies per question\n",
    "        messages_batches.extend(batch)  # flatten for vllm batch\n",
    "    return messages_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to run LLM for batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def chunked(iterable, size):\n",
    "    \"\"\"Yield successive chunks from iterable.\"\"\"\n",
    "    for i in range(0, len(iterable), size):\n",
    "        yield iterable[i:i + size]\n",
    "\n",
    "def run_llm_in_batches(messages_batches: List[list], batch_size: int = 48, group_size: int = 5) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Runs the llm_engine in fixed-size batches and groups responses for majority voting.\n",
    "\n",
    "    Args:\n",
    "        messages_batches (List[list]): List of chat-format messages (prompt per instance).\n",
    "        batch_size (int): Number of messages to send per call to llm_engine.\n",
    "        group_size (int): Number of completions per logical instance (for majority voting).\n",
    "\n",
    "    Returns:\n",
    "        grouped_responses (List[List[str]]): Responses grouped per question.\n",
    "    \"\"\"\n",
    "    all_responses = []\n",
    "\n",
    "    for batch in chunked(messages_batches, batch_size):\n",
    "        responses = llm_engine(batch)\n",
    "        all_responses.extend(responses)\n",
    "\n",
    "    # Group responses (e.g., for 5 votes per question)\n",
    "    grouped_responses = [all_responses[i:i + group_size] for i in range(0, len(all_responses), group_size)]\n",
    "\n",
    "    return grouped_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Majority voting in Grouped Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:45:33.817755Z",
     "iopub.status.busy": "2025-05-04T18:45:33.817178Z",
     "iopub.status.idle": "2025-05-04T18:45:33.821574Z",
     "shell.execute_reply": "2025-05-04T18:45:33.820921Z",
     "shell.execute_reply.started": "2025-05-04T18:45:33.817729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def aggregate_majority_votes(grouped_responses):\n",
    "    \"\"\"\n",
    "    Parses and performs majority voting with explanations on grouped LLM responses.\n",
    "\n",
    "    Args:\n",
    "        grouped_responses (List[List[str]]): Responses grouped per question.\n",
    "\n",
    "    Returns:\n",
    "        List[List[Tuple[str, int, int, str]]]: \n",
    "            For each question:\n",
    "                A list of tuples (rubric_text, majority_score, total, explanation).\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "\n",
    "    for group in grouped_responses:\n",
    "        parsed = parse_batch_evaluations(group)\n",
    "        rubric_scores = majority_vote_with_explanations(parsed)\n",
    "        final_results.append(rubric_scores)\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to print the final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:45:36.828360Z",
     "iopub.status.busy": "2025-05-04T18:45:36.827572Z",
     "iopub.status.idle": "2025-05-04T18:45:36.833864Z",
     "shell.execute_reply": "2025-05-04T18:45:36.833012Z",
     "shell.execute_reply.started": "2025-05-04T18:45:36.828334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def print_majority_vote_results(final_results, questions=None):\n",
    "    \"\"\"\n",
    "    Nicely prints rubric-wise majority scores and explanations.\n",
    "\n",
    "    Args:\n",
    "        final_results: List of lists of tuples (rubric_text, score, total, explanation)\n",
    "        questions: Optional list of question texts for headers\n",
    "    \"\"\"\n",
    "    for i, rubric_scores in enumerate(final_results):\n",
    "        if questions:\n",
    "            print(f\"\\n📌 Question {i+1}: {questions[i]}\")\n",
    "        else:\n",
    "            print(f\"\\n📌 Question {i+1}:\")\n",
    "\n",
    "        total_score = 0\n",
    "        total_possible = 0\n",
    "\n",
    "        for j, (rubric, score, total, explanation) in enumerate(rubric_scores):\n",
    "            print(f\"\\n🧾 Rubric {j+1}: {rubric}\")\n",
    "            print(f\"✅ Score: {score}/{total}\")\n",
    "            print(f\"🗒️ Explanation: {explanation}\")\n",
    "            total_score += score\n",
    "            total_possible += total\n",
    "\n",
    "        print(f\"\\n🏁 Final Score: {total_score}/{total_possible}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:50:02.839249Z",
     "iopub.status.busy": "2025-05-04T18:50:02.838489Z",
     "iopub.status.idle": "2025-05-04T18:51:15.852714Z",
     "shell.execute_reply": "2025-05-04T18:51:15.851852Z",
     "shell.execute_reply.started": "2025-05-04T18:50:02.839224Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Question 1:\n",
      "\n",
      "🧾 Rubric 1: 1. The student correctly identifies the integral for the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\).\n",
      "✅ Score: 4/4\n",
      "🗒️ Explanation: 1. The student correctly sets up the integral \\( A = \\int_{0}^{\\pi} \\sin x \\, dx \\) to find the area under the curve.\n",
      "\n",
      "🧾 Rubric 2: 2. The student uses the correct formula for integrating \\( \\sin x \\), which is \\( \\int \\sin x \\, dx = -\\cos x + C \\).\n",
      "✅ Score: 3/3\n",
      "🗒️ Explanation: 2. The student applies the correct integration formula \\( \\int \\sin x \\, dx = -\\cos x + C \\) and evaluates the definite integral from 0 to \\( \\pi \\).\n",
      "\n",
      "🧾 Rubric 3: 3. The student calculates the area correctly as 2 square units.\n",
      "✅ Score: 3/3\n",
      "🗒️ Explanation: 3. The student evaluates the definite integral correctly and arrives at the area of 2 square units.\n",
      "\n",
      "🏁 Final Score: 10/10\n",
      "--------------------------------------------------\n",
      "\n",
      "📌 Question 2:\n",
      "\n",
      "🧾 Rubric 1: 1. The student correctly identifies the given information: initial velocity (u=0 m/s), time (t=60 s), and final velocity (v=16.67 m/s).\n",
      "✅ Score: 3/3\n",
      "🗒️ Explanation: 1. The student correctly identifies the initial velocity, time, and final velocity.\n",
      "\n",
      "🧾 Rubric 2: 2. The student does not explicitly mention the formula for acceleration.\n",
      "✅ Score: 0/2\n",
      "🗒️ Explanation: 2. The formula for acceleration (a = (v - u) / t) is not explicitly mentioned.\n",
      "\n",
      "🧾 Rubric 3: 3. The student uses the correct formula for acceleration, a = (v - u) / t.\n",
      "✅ Score: 3/3\n",
      "🗒️ Explanation: 3. The student correctly applies the formula for acceleration.\n",
      "\n",
      "🧾 Rubric 4: 4. The student calculates the correct acceleration: a = (16.67 m/s - 0 m/s) / 60 s = 0.278 m/s².\n",
      "✅ Score: 2/2\n",
      "🗒️ Explanation: 4. The student correctly calculates the acceleration.\n",
      "\n",
      "🏁 Final Score: 8/10\n",
      "--------------------------------------------------\n",
      "\n",
      "📌 Question 3:\n",
      "\n",
      "🧾 Rubric 1: 1. The student did not provide the correct answer.\n",
      "✅ Score: 0/2\n",
      "🗒️ Explanation: 1. The time period of a simple pendulum is given by the formula \\( T = 2\\pi \\sqrt{\\frac{L}{g}} \\), where \\( L \\) is the length of the pendulum and \\( g \\) is the acceleration due to gravity. In space, the acceleration due to gravity is significantly reduced or can be considered zero in a microgravity environment. Therefore, the time period of the pendulum in space would be undefined or effectively infinite because the pendulum would not swing without gravity.\n",
      "\n",
      "🏁 Final Score: 0/2\n",
      "--------------------------------------------------\n",
      "\n",
      "📌 Question 4:\n",
      "\n",
      "🧾 Rubric 1: 1. The student correctly identifies the integral that represents the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( 2\\pi \\).\n",
      "✅ Score: 4/4\n",
      "🗒️ Explanation: 1. The student correctly sets up the integral \\( \\int_{0}^{2\\pi} \\sin x \\, dx \\) to find the area under the curve.\n",
      "\n",
      "🧾 Rubric 2: 2. The student uses the correct formula for integrating \\( \\sin x \\), which is \\( \\int \\sin x \\, dx = -\\cos x + C \\).\n",
      "✅ Score: 3/3\n",
      "🗒️ Explanation: 2. The student correctly applies the integral formula \\( \\int \\sin x \\, dx = -\\cos x + C \\).\n",
      "\n",
      "🧾 Rubric 3: 3. The student calculates the definite integral but arrives at an incorrect conclusion about the area. The integral evaluates to zero, but this does not represent the total area under the curve. The area under the curve should be calculated as the sum of the absolute values of the areas above and below the x-axis.\n",
      "✅ Score: 0/3\n",
      "🗒️ Explanation: 3. The student's calculation of the integral is correct, but the interpretation is incorrect. The integral evaluates to zero because the positive and negative areas cancel each other out. However, the question asks for the total area, which should be the sum of the absolute values of the areas above and below the x-axis. The correct total area is \\( 4 \\) square units (since the area under one complete sine wave from \\( 0 \\) to \\( \\pi \\) is \\( 2 \\) square units, and there are two such waves from \\( 0 \\) to \\( 2\\pi \\)).\n",
      "\n",
      "🏁 Final Score: 7/10\n",
      "--------------------------------------------------\n",
      "\n",
      "📌 Question 5:\n",
      "\n",
      "🧾 Rubric 1: 2. There are several grammatical errors and misspellings in the text. For example, \"Revolushion,\" \"insted,\" \"spreaded,\" and \"help make.\"\n",
      "✅ Score: 1/2\n",
      "🗒️ Explanation: 1. The paragraph correctly identifies the period and the shift from handcraft to machine production. However, the statement about nothing being possible without the Industrial Revolution is an exaggeration and not historically accurate.\n",
      "\n",
      "🧾 Rubric 2: 4. The content stays focused on the Industrial Revolution, although it does not provide a detailed timeline or specific examples.\n",
      "✅ Score: 2/2\n",
      "🗒️ Explanation: 2. There are several grammatical errors and misspellings, which affect the readability and correctness of the text.\n",
      "\n",
      "🧾 Rubric 3: 5. The paragraph is brief but includes key details about the impact of the Industrial Revolution.\n",
      "✅ Score: 2/2\n",
      "🗒️ Explanation: 3. The ideas are generally clear but are not logically connected. The paragraph jumps from one idea to another without a clear flow, making it less coherent.\n",
      "\n",
      "🧾 Rubric 4: 4. The content stays focused on the Industrial Revolution, though it does not provide specific examples or details.\n",
      "✅ Score: 2/2\n",
      "🗒️ Explanation: 4. The content stays focused on the Industrial Revolution, discussing its impact on technology, factories, pollution, and working conditions.\n",
      "\n",
      "🧾 Rubric 5: 5. The paragraph is brief but includes key details about the impact of the Industrial Revolution.\n",
      "✅ Score: 2/2\n",
      "🗒️ Explanation: 5. The paragraph is brief and includes key details about the impact of the Industrial Revolution, such as new technology, factories, pollution, and poor working conditions.\n",
      "\n",
      "🏁 Final Score: 9/10\n",
      "--------------------------------------------------\n",
      "\n",
      "📌 Question 6:\n",
      "\n",
      "🧾 Rubric 1: 1. The student does not explicitly mention resonance, delocalization, aromaticity, or Huckel's rule.\n",
      "✅ Score: 0/5\n",
      "🗒️ Explanation: 1. The student does not provide a clear explanation of why benzene is stable due to resonance, delocalization, or aromaticity. These concepts are crucial for understanding the stability of benzene.\n",
      "\n",
      "🧾 Rubric 2: 2. The student shows some understanding of electron delocalization by mentioning that the double bonds stay in place and the structure doesn't change. However, the explanation is not precise enough to fully capture the concept of electron delocalization.\n",
      "✅ Score: 1/3\n",
      "🗒️ Explanation: 2. While the student mentions that the double bonds stay in place, this is not a precise explanation of electron delocalization. The student also mentions the ring structure, which helps in understanding the stability but is not a complete explanation.\n",
      "\n",
      "🧾 Rubric 3: 3. The student uses some correct scientific terms like π bonds but does not use terms like resonance or aromaticity.\n",
      "✅ Score: 1/2\n",
      "🗒️ Explanation: 3. The student uses terms like π bonds but does not use terms like resonance or aromaticity, which are essential for a complete explanation.\n",
      "\n",
      "🏁 Final Score: 2/10\n",
      "--------------------------------------------------\n",
      "\n",
      "📌 Question 7:\n",
      "\n",
      "🧾 Rubric 1: 1. The student has provided accurate information about Sundarban, including its location, characteristics, and wildlife.\n",
      "✅ Score: 4/4\n",
      "🗒️ Explanation: 1. The student correctly mentioned Sundarban as the world's largest mangrove forest, located in both Bangladesh and India. They also mentioned rare animals like Royal Bengal Tiger, spotted deer, and crocodiles.\n",
      "\n",
      "🧾 Rubric 2: 2. The paragraph is focused on Sundarban and is relevant to the topic.\n",
      "✅ Score: 2/2\n",
      "🗒️ Explanation: 2. The paragraph is entirely about Sundarban, discussing its characteristics and importance.\n",
      "\n",
      "🧾 Rubric 3: 3. The language construction and grammar are correct.\n",
      "✅ Score: 2/2\n",
      "🗒️ Explanation: 3. The writing is grammatically correct with proper spelling and sentence structure.\n",
      "\n",
      "🧾 Rubric 4: 4. The student has used appropriate terminology related to environment, wildlife, and geography.\n",
      "✅ Score: 2/2\n",
      "🗒️ Explanation: 4. The student used appropriate terms such as \"ম্যানগ্রোভ বন\", \"রূপকর্ম\", \"প্রাকৃতিক দুর্যোগ\", and \"উপকূলীয় এলাকা\".\n",
      "\n",
      "🏁 Final Score: 10/10\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "messages_batches = batch_messages_together(questions_answers_list)\n",
    "grouped_outputs = run_llm_in_batches(messages_batches, batch_size=48, group_size=5)\n",
    "final_results = aggregate_majority_votes(grouped_outputs)\n",
    "print_majority_vote_results(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install flask pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Optional: Clean up old numpy to avoid ABI mismatch\n",
    "!pip uninstall -y numpy\n",
    "\n",
    "# ✅ Reinstall numpy first to ensure ABI compatibility\n",
    "!pip install numpy==1.26.4 --force-reinstall\n",
    "\n",
    "# ✅ Install vLLM and compatible versions\n",
    "!pip install -U transformers==4.45.2 vllm==0.6.0\n",
    "!pip install -U torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Optional but helpful:\n",
    "!pip uninstall -y pynvml\n",
    "!pip install nvidia-ml-py\n",
    "\n",
    "# For quantized model support:\n",
    "!pip install optimum auto-gptq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Optional\n",
    "import torch\n",
    "import vllm\n",
    "from vllm import SamplingParams\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List\n",
    "\n",
    "# model_id = \"Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\"\n",
    "model_id = \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n",
    "\n",
    "llm = vllm.LLM(\n",
    "    model_id,\n",
    "    quantization=\"awq\",\n",
    "    max_model_len=4096,\n",
    "    enable_prefix_caching=True,\n",
    "    tensor_parallel_size=torch.cuda.device_count(),\n",
    ")\n",
    "\n",
    "tokenizer = llm.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:48:37.759577Z",
     "iopub.status.busy": "2025-05-04T18:48:37.759196Z",
     "iopub.status.idle": "2025-05-04T18:48:37.779662Z",
     "shell.execute_reply": "2025-05-04T18:48:37.779058Z",
     "shell.execute_reply.started": "2025-05-04T18:48:37.759546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"You are an evaluator that checks student answers based on the given question and rubric.\n",
    "\n",
    "For every input, follow these steps in order:\n",
    "1. **Evaluation**: Go through each rubric item and assign marks accordingly. \n",
    "   - Enclose marks in `<marks>` tags like this: `<marks>1/2</marks>`.\n",
    "2. **Explanation**: For each rubric item, explain the reasoning behind the assigned marks.\n",
    "3. **Final Score**: Sum the individual rubric scores and provide a total, using `<score>` tags. \n",
    "   - Format: `Final score: <score>7/8</score>`\n",
    "\n",
    "Always use these three clearly labeled sections:  \n",
    "`Evaluation:`  \n",
    "`Explanation:`  \n",
    "`Final Score:`  \n",
    "\n",
    "Be objective, fair, and detailed. Do not skip any rubric.\n",
    "\n",
    "Below are examples for you to learn the format:\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "question = Find the derivative of f(x) = x³ + 3x² + 1.\n",
    "\n",
    "rubric = \"1. States the general power rule (2 points)\n",
    "2. Applies the power rule to x³ correctly (2 points)\n",
    "3. Applies the power rule to 3x² correctly (2 points)\n",
    "4. Simplifies the derivative properly (2 points)\n",
    "\n",
    "answer = f'(x) = 3x² + 6x\n",
    "\n",
    "Response:\n",
    "\n",
    "Evaluation:\n",
    "1. The student did not explicitly state the general power rule. <marks>0/2</marks>\n",
    "2. The student correctly applied the power rule to x³. <marks>2/2</marks>\n",
    "3. The student correctly applied the power rule to 3x². <marks>2/2</marks>\n",
    "4. The simplification is correct. <marks>2/2</marks>\n",
    "\n",
    "Explanation:\n",
    "1. The general rule (d/dx[xⁿ] = n·xⁿ⁻¹) was not stated, though applied correctly.\n",
    "2. d/dx[x³] = 3x², which the student wrote.\n",
    "3. d/dx[3x²] = 6x, which is also correct.\n",
    "4. There are no like terms, and the expression is simplified properly.\n",
    "\n",
    "Final Score: <score>6/8</score>\n",
    "\n",
    "**Example 2:**\n",
    "\n",
    "question = What is the capital of France?\n",
    "\n",
    "rubric = 1. Identifies the capital correctly (2 points)\n",
    "2. Provides any additional context (1 point)\n",
    "\n",
    "answer = Paris is the capital of France. It is known for the Eiffel Tower.\n",
    "\n",
    "Response:\n",
    "\n",
    "Evaluation:\n",
    "1. Correct capital is stated. <marks>2/2</marks>\n",
    "2. Additional context about Eiffel Tower is provided. <marks>1/1</marks>\n",
    "\n",
    "Explanation:\n",
    "1. Paris is indeed the capital of France.\n",
    "2. Mentioning the Eiffel Tower adds informative context about the city.\n",
    "\n",
    "Final Score: <score>3/3</score>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def llm_engine(\n",
    "    list_of_messages: List[List[dict]],\n",
    "    stop_sequences: Optional[List[str]] = None,\n",
    "    start_sequence: Optional[str] = None,\n",
    "    temperature: float = 0.2,\n",
    "    max_tokens: int = 2048\n",
    ") -> List[str]:\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,\n",
    "        max_tokens=max_tokens,\n",
    "        stop=stop_sequences,\n",
    "        include_stop_str_in_output=True,\n",
    "    )\n",
    "\n",
    "    prompts = [\n",
    "        tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        for messages in list_of_messages\n",
    "    ]\n",
    "\n",
    "    if start_sequence:\n",
    "        prompts = [prompt + start_sequence for prompt in prompts]\n",
    "\n",
    "    outputs = llm.generate(prompts, sampling_params, use_tqdm=False)\n",
    "    responses = [o.outputs[0].text.strip() for o in outputs]\n",
    "\n",
    "    if start_sequence:\n",
    "        responses = [start_sequence + response for response in responses]\n",
    "\n",
    "    return responses\n",
    "\n",
    "def parse_evaluation_response(response: str):\n",
    "    \"\"\"\n",
    "    Extracts rubric-wise scores, explanations, and total score from the model's output.\n",
    "    Assumes the structure:\n",
    "    Evaluation:\n",
    "    1. explanation <marks>X/Y</marks>\n",
    "    2. explanation <marks>X/Y</marks>\n",
    "    ...\n",
    "    Explanation:\n",
    "    1. ...\n",
    "    2. ...\n",
    "    Final Score:\n",
    "    The final score is: <score>X/Y</score>\n",
    "    \"\"\"\n",
    "    # --- Extract rubric-wise scores with explanations ---\n",
    "    eval_section = re.search(r\"Evaluation:(.*?)(Explanation:|Final Score:)\", response, re.DOTALL)\n",
    "    explanation_section = re.search(r\"Explanation:(.*?)(Final Score:|$)\", response, re.DOTALL)\n",
    "    final_score = re.search(r\"<score>(\\d+)\\s*/\\s*(\\d+)</score>\", response)\n",
    "\n",
    "    rubric_scores = []\n",
    "    if eval_section:\n",
    "        lines = eval_section.group(1).strip().split(\"\\n\")\n",
    "        for line in lines:\n",
    "            match = re.search(r\"(.*)<marks>(\\d+)\\s*/\\s*(\\d+)</marks>\", line.strip())\n",
    "            if match:\n",
    "                rubric_text = match.group(1).strip()\n",
    "                score = int(match.group(2))\n",
    "                total = int(match.group(3))\n",
    "                rubric_scores.append((rubric_text, score, total))\n",
    "\n",
    "    explanations = []\n",
    "    if explanation_section:\n",
    "        lines = explanation_section.group(1).strip().split(\"\\n\")\n",
    "        explanations = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    total_score = None\n",
    "    if final_score:\n",
    "        total_score = (int(final_score.group(1)), int(final_score.group(2)))\n",
    "\n",
    "    return rubric_scores, explanations, total_score\n",
    "\n",
    "def parse_batch_evaluations(responses: list[str]):\n",
    "    \"\"\"\n",
    "    Processes a list of model responses, extracting:\n",
    "    - Rubric-wise evaluations (text + marks)\n",
    "    - Explanations\n",
    "    - Final scores\n",
    "    Returns a list of dicts, one per response.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for idx, response in enumerate(responses):\n",
    "        rubric_scores, explanations, total_score = parse_evaluation_response(response)\n",
    "\n",
    "        entry = {\n",
    "            \"response_index\": idx,\n",
    "            \"rubric_scores\": rubric_scores,       # List of (rubric_text, score, total)\n",
    "            \"explanations\": explanations,         # List of explanation strings\n",
    "            \"final_score\": total_score            # Tuple (score, total) or None\n",
    "        }\n",
    "\n",
    "        results.append(entry)\n",
    "\n",
    "    return results\n",
    "\n",
    "def make_messages(question: str, answer: str, rubric: str) -> list[dict]:\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"QUESTION:\n",
    "{question}\n",
    "\n",
    "STUDENT ANSWER:\n",
    "{answer}\n",
    "\n",
    "RUBRIC:\n",
    "{rubric}\n",
    "\"\"\"}\n",
    "    ]\n",
    "\n",
    "def majority_vote_with_explanations(parsed_batch):\n",
    "    \"\"\"\n",
    "    Takes parsed batch outputs and returns majority-voted rubric scores with explanations.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: (rubric_text, voted_score, total, explanation)\n",
    "    \"\"\"\n",
    "    rubric_scores = defaultdict(list)  # i -> [(score, total)]\n",
    "    rubric_explanations = defaultdict(list)  # i -> [explanation]\n",
    "    rubric_texts = []\n",
    "\n",
    "    for entry in parsed_batch:\n",
    "        for i, (rubric_text, score, total) in enumerate(entry['rubric_scores']):\n",
    "            rubric_scores[i].append((score, total))\n",
    "            rubric_explanations[i].append(entry['explanations'][i])\n",
    "            if len(rubric_texts) <= i:\n",
    "                rubric_texts.append(rubric_text)\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(rubric_scores)):\n",
    "        # Majority vote on score\n",
    "        score_counter = Counter(rubric_scores[i])\n",
    "        (voted_score, voted_total), _ = score_counter.most_common(1)[0]\n",
    "\n",
    "        # Most common explanation\n",
    "        explanation_counter = Counter(rubric_explanations[i])\n",
    "        voted_explanation, _ = explanation_counter.most_common(1)[0]\n",
    "\n",
    "        results.append((rubric_texts[i], voted_score, voted_total, voted_explanation))\n",
    "\n",
    "    return results\n",
    "\n",
    "def batch_messages_together(questions_answers_list):\n",
    "    messages_batches = []\n",
    "    for qa in questions_answers_list: # This list is a list of dictionaries(for now)\n",
    "        question, answer, rubric = qa[\"question\"], qa[\"answer\"], qa[\"rubric\"]\n",
    "        single_message = make_messages(question, answer, rubric)\n",
    "        batch = [single_message] * 5  # 5 copies per question\n",
    "        messages_batches.extend(batch)  # flatten for vllm batch\n",
    "    return messages_batches\n",
    "\n",
    "def chunked(iterable, size):\n",
    "    \"\"\"Yield successive chunks from iterable.\"\"\"\n",
    "    for i in range(0, len(iterable), size):\n",
    "        yield iterable[i:i + size]\n",
    "\n",
    "def run_llm_in_batches(messages_batches: List[list], batch_size: int = 48, group_size: int = 5) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Runs the llm_engine in fixed-size batches and groups responses for majority voting.\n",
    "\n",
    "    Args:\n",
    "        messages_batches (List[list]): List of chat-format messages (prompt per instance).\n",
    "        batch_size (int): Number of messages to send per call to llm_engine.\n",
    "        group_size (int): Number of completions per logical instance (for majority voting).\n",
    "\n",
    "    Returns:\n",
    "        grouped_responses (List[List[str]]): Responses grouped per question.\n",
    "    \"\"\"\n",
    "    all_responses = []\n",
    "\n",
    "    for batch in chunked(messages_batches, batch_size):\n",
    "        responses = llm_engine(batch)\n",
    "        all_responses.extend(responses)\n",
    "\n",
    "    # Group responses (e.g., for 5 votes per question)\n",
    "    grouped_responses = [all_responses[i:i + group_size] for i in range(0, len(all_responses), group_size)]\n",
    "\n",
    "    return grouped_responses\n",
    "\n",
    "def aggregate_majority_votes(grouped_responses):\n",
    "    \"\"\"\n",
    "    Parses and performs majority voting with explanations on grouped LLM responses.\n",
    "\n",
    "    Args:\n",
    "        grouped_responses (List[List[str]]): Responses grouped per question.\n",
    "\n",
    "    Returns:\n",
    "        List[List[Tuple[str, int, int, str]]]: \n",
    "            For each question:\n",
    "                A list of tuples (rubric_text, majority_score, total, explanation).\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "\n",
    "    for group in grouped_responses:\n",
    "        parsed = parse_batch_evaluations(group)\n",
    "        rubric_scores = majority_vote_with_explanations(parsed)\n",
    "        final_results.append(rubric_scores)\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:59:35.317605Z",
     "iopub.status.busy": "2025-05-04T18:59:35.316576Z",
     "iopub.status.idle": "2025-05-04T18:59:35.377219Z",
     "shell.execute_reply": "2025-05-04T18:59:35.376650Z",
     "shell.execute_reply.started": "2025-05-04T18:59:35.317561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/evaluate\", methods=[\"POST\"])\n",
    "def evaluate():\n",
    "    data = request.get_json()\n",
    "    # data = [\n",
    "    #     {\n",
    "    #         \"question\":\"\",\n",
    "    #         \"answer\":\"\",\n",
    "    #         \"rubric\":\"\"\n",
    "    #     },\n",
    "    #     {\n",
    "    #         \"question\":\"\",\n",
    "    #         \"answer\":\"\",\n",
    "    #         \"rubric\":\"\"\n",
    "    #     }\n",
    "    # ]\n",
    "    \n",
    "    messages_batches = batch_messages_together(data)\n",
    "    grouped_outputs = run_llm_in_batches(messages_batches, batch_size=48, group_size=5)\n",
    "    final_results = aggregate_majority_votes(grouped_outputs)\n",
    "    \n",
    "    # Structure for return data\n",
    "    response_data = []\n",
    "    \n",
    "    for i, question_results in enumerate(final_results):\n",
    "        question_data = {\n",
    "            \"question_index\": i,\n",
    "            \"rubric_scores\": [],\n",
    "            \"total_score\": 0,\n",
    "            \"total_possible\": 0\n",
    "        }\n",
    "        \n",
    "        for rubric_text, score, total, explanation in question_results:\n",
    "            question_data[\"rubric_scores\"].append({\n",
    "                \"rubric_text\": rubric_text,\n",
    "                \"score\": score,\n",
    "                \"total\": total,\n",
    "                \"explanation\": explanation\n",
    "            })\n",
    "            question_data[\"total_score\"] += score\n",
    "            question_data[\"total_possible\"] += total\n",
    "            \n",
    "        response_data.append(question_data)\n",
    "    \n",
    "    return jsonify(response_data)\n",
    "\n",
    "@app.route(\"/evaluate_question_set\", methods=[\"POST\"])\n",
    "def evaluate_question_set():\n",
    "    data = request.get_json()\n",
    "    # Expected format:\n",
    "    # {\n",
    "    #     \"question_set_id\": \"uuid\",\n",
    "    #     \"submission_id\": \"uuid\",\n",
    "    #     \"questions\": [\n",
    "    #         {\n",
    "    #             \"question_id\": \"uuid\",\n",
    "    #             \"question\": \"text\",\n",
    "    #             \"answer\": \"text\",\n",
    "    #             \"rubric\": \"text\"\n",
    "    #         },\n",
    "    #         ...\n",
    "    #     ]\n",
    "    # }\n",
    "    \n",
    "    # Prepare data for evaluation\n",
    "    eval_data = []\n",
    "    for question_data in data[\"questions\"]:\n",
    "        eval_data.append({\n",
    "            \"question\": question_data[\"question\"],\n",
    "            \"answer\": question_data[\"answer\"],\n",
    "            \"rubric\": question_data[\"rubric\"]\n",
    "        })\n",
    "    \n",
    "    # Evaluate all questions in the set\n",
    "    messages_batches = batch_messages_together(eval_data)\n",
    "    grouped_outputs = run_llm_in_batches(messages_batches, batch_size=48, group_size=5)\n",
    "    final_results = aggregate_majority_votes(grouped_outputs)\n",
    "    \n",
    "    # Structure results\n",
    "    response_data = {\n",
    "        \"question_set_id\": data[\"question_set_id\"],\n",
    "        \"submission_id\": data[\"submission_id\"],\n",
    "        \"overall_score\": 0,\n",
    "        \"overall_possible\": 0,\n",
    "        \"question_evaluations\": []\n",
    "    }\n",
    "    \n",
    "    for i, (question_results, question_data) in enumerate(zip(final_results, data[\"questions\"])):\n",
    "        question_eval = {\n",
    "            \"question_id\": question_data[\"question_id\"],\n",
    "            \"rubric_scores\": [],\n",
    "            \"total_score\": 0,\n",
    "            \"total_possible\": 0\n",
    "        }\n",
    "        \n",
    "        for rubric_text, score, total, explanation in question_results:\n",
    "            question_eval[\"rubric_scores\"].append({\n",
    "                \"rubric_text\": rubric_text,\n",
    "                \"score\": score,\n",
    "                \"total\": total,\n",
    "                \"explanation\": explanation\n",
    "            })\n",
    "            question_eval[\"total_score\"] += score\n",
    "            question_eval[\"total_possible\"] += total\n",
    "            \n",
    "        response_data[\"question_evaluations\"].append(question_eval)\n",
    "        response_data[\"overall_score\"] += question_eval[\"total_score\"]\n",
    "        response_data[\"overall_possible\"] += question_eval[\"total_possible\"]\n",
    "    \n",
    "    return jsonify(response_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:59:38.321042Z",
     "iopub.status.busy": "2025-05-04T18:59:38.320477Z",
     "iopub.status.idle": "2025-05-04T18:59:38.912833Z",
     "shell.execute_reply": "2025-05-04T18:59:38.912127Z",
     "shell.execute_reply.started": "2025-05-04T18:59:38.321015Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8 (_monitor_process):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\", line 139, in _monitor_process\n",
      "    self._log_line(self.proc.stdout.readline())\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/encodings/ascii.py\", line 26, in decode\n",
      "    return codecs.ascii_decode(input, self.errors)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'ascii' codec can't decode byte 0xc2 in position 184: ordinal not in range(128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your public URL is: NgrokTunnel: \"https://a23a-34-59-154-2.ngrok-free.app\" -> \"http://localhost:5000\"\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok,conf\n",
    "import threading\n",
    "\n",
    "conf.get_default().auth_token = \"2wJ6kv95fYPhMLm6aTNvpKvdVip_6R2DJ22BBvoK8MKzhBLX8\"\n",
    "\n",
    "ngrok.kill()\n",
    "\n",
    "# Expose the Flask app to the internet\n",
    "public_url = ngrok.connect(5000)\n",
    "print(f\"Your public URL is: {public_url}\")\n",
    "\n",
    "# Run Flask in a separate thread to avoid blocking\n",
    "threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
