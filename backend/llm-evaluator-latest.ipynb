{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pure Vibe Coding ","metadata":{}},{"cell_type":"markdown","source":"## Installation and Imports","metadata":{}},{"cell_type":"code","source":"%%capture\n# Optional: Clean up old numpy to avoid ABI mismatch\n!pip uninstall -y numpy\n\n# ✅ Reinstall numpy first to ensure ABI compatibility\n!pip install numpy==1.26.4 --force-reinstall\n\n# ✅ Install vLLM and compatible versions\n!pip install -U transformers==4.45.2 vllm==0.6.0\n!pip install -U torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n\n# Optional but helpful:\n!pip uninstall -y pynvml\n!pip install nvidia-ml-py\n\n# For quantized model support:\n!pip install optimum auto-gptq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T09:46:11.569938Z","iopub.execute_input":"2025-05-03T09:46:11.570261Z","iopub.status.idle":"2025-05-03T09:51:09.750219Z","shell.execute_reply.started":"2025-05-03T09:46:11.570235Z","shell.execute_reply":"2025-05-03T09:51:09.749202Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import re\nfrom typing import List, Optional\nimport torch\nimport vllm\nfrom vllm import SamplingParams\nfrom collections import defaultdict, Counter\nfrom typing import List","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T09:51:09.751569Z","iopub.execute_input":"2025-05-03T09:51:09.751842Z","iopub.status.idle":"2025-05-03T09:51:41.055927Z","shell.execute_reply.started":"2025-05-03T09:51:09.751818Z","shell.execute_reply":"2025-05-03T09:51:41.055358Z"}},"outputs":[{"name":"stderr","text":"2025-05-03 09:51:19.524516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746265879.927210      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746265880.057194      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Loading Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"# model_id = \"Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\"\nmodel_id = \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n\nllm = vllm.LLM(\n    model_id,\n    quantization=\"awq\",\n    max_model_len=4096,\n    enable_prefix_caching=True,\n    tensor_parallel_size=torch.cuda.device_count(),\n)\n\ntokenizer = llm.get_tokenizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T09:51:41.056686Z","iopub.execute_input":"2025-05-03T09:51:41.057374Z","iopub.status.idle":"2025-05-03T09:53:53.068875Z","shell.execute_reply.started":"2025-05-03T09:51:41.057352Z","shell.execute_reply":"2025-05-03T09:53:53.067977Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba609ee61b834c1b99751f828d386731"}},"metadata":{}},{"name":"stdout","text":"WARNING 05-03 09:51:41 config.py:330] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\nINFO 05-03 09:51:41 config.py:890] Defaulting to use mp for distributed inference\nINFO 05-03 09:51:41 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='Qwen/Qwen2.5-14B-Instruct-AWQ', speculative_config=None, tokenizer='Qwen/Qwen2.5-14B-Instruct-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-14B-Instruct-AWQ, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=True, use_async_output_proc=True)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09e20717439e43c0bca25a1168126488"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a5e581c48134f1f8396b8b9331ce888"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8921d126bc064da0b4c92a82a35d13d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f080b9278c4fdaa8de20dbdc2c3b63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"689296299dba402ba0c01f2a1db2e9ae"}},"metadata":{}},{"name":"stdout","text":"WARNING 05-03 09:51:42 multiproc_gpu_executor.py:56] Reducing Torch parallelism from 2 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\nINFO 05-03 09:51:42 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\nINFO 05-03 09:51:43 selector.py:217] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\nINFO 05-03 09:51:43 selector.py:116] Using XFormers backend.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:51:43 selector.py:217] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:51:43 selector.py:116] Using XFormers backend.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m /usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m   @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m /usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m   @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m ","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n","output_type":"stream"},{"name":"stdout","text":"INFO 05-03 09:51:44 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\nINFO 05-03 09:51:44 utils.py:977] Found nccl from library libnccl.so.2\nINFO 05-03 09:51:44 pynccl.py:63] vLLM is using nccl==2.20.5\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:51:44 utils.py:977] Found nccl from library libnccl.so.2\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:51:44 pynccl.py:63] vLLM is using nccl==2.20.5\nINFO 05-03 09:51:44 custom_all_reduce_utils.py:204] generating GPU P2P access cache in /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\nINFO 05-03 09:52:07 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\nWARNING 05-03 09:52:07 custom_all_reduce.py:131] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:52:07 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m WARNING 05-03 09:52:07 custom_all_reduce.py:131] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\nINFO 05-03 09:52:07 shm_broadcast.py:235] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7a82b4a61ed0>, local_subscribe_port=59683, remote_subscribe_port=None)\nINFO 05-03 09:52:07 model_runner.py:915] Starting to load model Qwen/Qwen2.5-14B-Instruct-AWQ...\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:52:07 model_runner.py:915] Starting to load model Qwen/Qwen2.5-14B-Instruct-AWQ...\nINFO 05-03 09:52:07 selector.py:217] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:52:07 selector.py:116] Using XFormers backend.\nINFO 05-03 09:52:07 selector.py:217] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:52:07 selector.py:116] Using XFormers backend.\nINFO 05-03 09:52:07 weight_utils.py:236] Using model weights format ['*.safetensors']\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:52:07 weight_utils.py:236] Using model weights format ['*.safetensors']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c735620333de401ea9169eff59a6010d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0a92f918a5e4f2a934a7fdcb16e7636"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/2.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3b93e9122214005b18b98babc1304c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/107k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca29921acf6f4ec593885a1275d6dd55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1838d5531bb045369e8c87a69f455001"}},"metadata":{}},{"name":"stdout","text":"INFO 05-03 09:52:51 model_runner.py:926] Loading model weights took 4.6719 GB\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:52:54 model_runner.py:926] Loading model weights took 4.6719 GB\nINFO 05-03 09:52:57 distributed_gpu_executor.py:57] # GPU blocks: 3965, # CPU blocks: 2730\nINFO 05-03 09:53:03 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\nINFO 05-03 09:53:03 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:53:03 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:53:03 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\nINFO 05-03 09:53:53 model_runner.py:1335] Graph capturing finished in 49 secs.\n\u001b[1;36m(VllmWorkerProcess pid=167)\u001b[0;0m INFO 05-03 09:53:53 model_runner.py:1335] Graph capturing finished in 49 secs.\nINFO 05-03 09:53:53 block_manager_v1.py:263] Automatic prefix caching is enabled.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Defining System Prompt","metadata":{}},{"cell_type":"code","source":"SYS_PROMPT = \"\"\"You are an evaluator that checks student answers based on the given question and rubric.\n\nFor every input, follow these steps in order:\n1. **Evaluation**: Go through each rubric item and assign marks accordingly. \n   - Enclose marks in `<marks>` tags like this: `<marks>1/2</marks>`.\n2. **Explanation**: For each rubric item, explain the reasoning behind the assigned marks.\n3. **Final Score**: Sum the individual rubric scores and provide a total, using `<score>` tags. \n   - Format: `Final score: <score>7/8</score>`\n\nAlways use these three clearly labeled sections:  \n`Evaluation:`  \n`Explanation:`  \n`Final Score:`  \n\nBe objective, fair, and detailed. Do not skip any rubric.\n\nBelow are examples for you to learn the format:\n\n**Example 1:**\n\nquestion = Find the derivative of f(x) = x³ + 3x² + 1.\n\nrubric = \"1. States the general power rule (2 points)\n2. Applies the power rule to x³ correctly (2 points)\n3. Applies the power rule to 3x² correctly (2 points)\n4. Simplifies the derivative properly (2 points)\n\nanswer = f'(x) = 3x² + 6x\n\nResponse:\n\nEvaluation:\n1. The student did not explicitly state the general power rule. <marks>0/2</marks>\n2. The student correctly applied the power rule to x³. <marks>2/2</marks>\n3. The student correctly applied the power rule to 3x². <marks>2/2</marks>\n4. The simplification is correct. <marks>2/2</marks>\n\nExplanation:\n1. The general rule (d/dx[xⁿ] = n·xⁿ⁻¹) was not stated, though applied correctly.\n2. d/dx[x³] = 3x², which the student wrote.\n3. d/dx[3x²] = 6x, which is also correct.\n4. There are no like terms, and the expression is simplified properly.\n\nFinal Score: <score>6/8</score>\n\n**Example 2:**\n\nquestion = What is the capital of France?\n\nrubric = 1. Identifies the capital correctly (2 points)\n2. Provides any additional context (1 point)\n\nanswer = Paris is the capital of France. It is known for the Eiffel Tower.\n\nResponse:\n\nEvaluation:\n1. Correct capital is stated. <marks>2/2</marks>\n2. Additional context about Eiffel Tower is provided. <marks>1/1</marks>\n\nExplanation:\n1. Paris is indeed the capital of France.\n2. Mentioning the Eiffel Tower adds informative context about the city.\n\nFinal Score: <score>3/3</score>\n\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T09:53:53.071841Z","iopub.execute_input":"2025-05-03T09:53:53.072133Z","iopub.status.idle":"2025-05-03T09:53:53.077461Z","shell.execute_reply.started":"2025-05-03T09:53:53.072094Z","shell.execute_reply":"2025-05-03T09:53:53.076727Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## LLM Engine","metadata":{}},{"cell_type":"code","source":"def llm_engine(\n    list_of_messages: List[List[dict]],\n    stop_sequences: Optional[List[str]] = None,\n    start_sequence: Optional[str] = None,\n    temperature: float = 0.2,\n    max_tokens: int = 2048\n) -> List[str]:\n    sampling_params = SamplingParams(\n        temperature=temperature,\n        top_p=0.9,\n        max_tokens=max_tokens,\n        stop=stop_sequences,\n        include_stop_str_in_output=True,\n    )\n\n    prompts = [\n        tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n        for messages in list_of_messages\n    ]\n\n    if start_sequence:\n        prompts = [prompt + start_sequence for prompt in prompts]\n\n    outputs = llm.generate(prompts, sampling_params, use_tqdm=False)\n    responses = [o.outputs[0].text.strip() for o in outputs]\n\n    if start_sequence:\n        responses = [start_sequence + response for response in responses]\n\n    return responses\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T09:53:53.078048Z","iopub.execute_input":"2025-05-03T09:53:53.078353Z","iopub.status.idle":"2025-05-03T09:53:53.106011Z","shell.execute_reply.started":"2025-05-03T09:53:53.078337Z","shell.execute_reply":"2025-05-03T09:53:53.105406Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Parsing Raw Responses","metadata":{}},{"cell_type":"code","source":"def parse_evaluation_response(response: str):\n    \"\"\"\n    Extracts rubric-wise scores, explanations, and total score from the model's output.\n    Assumes the structure:\n    Evaluation:\n    1. explanation <marks>X/Y</marks>\n    2. explanation <marks>X/Y</marks>\n    ...\n    Explanation:\n    1. ...\n    2. ...\n    Final Score:\n    The final score is: <score>X/Y</score>\n    \"\"\"\n    # --- Extract rubric-wise scores with explanations ---\n    eval_section = re.search(r\"Evaluation:(.*?)(Explanation:|Final Score:)\", response, re.DOTALL)\n    explanation_section = re.search(r\"Explanation:(.*?)(Final Score:|$)\", response, re.DOTALL)\n    final_score = re.search(r\"<score>(\\d+)\\s*/\\s*(\\d+)</score>\", response)\n\n    rubric_scores = []\n    if eval_section:\n        lines = eval_section.group(1).strip().split(\"\\n\")\n        for line in lines:\n            match = re.search(r\"(.*)<marks>(\\d+)\\s*/\\s*(\\d+)</marks>\", line.strip())\n            if match:\n                rubric_text = match.group(1).strip()\n                score = int(match.group(2))\n                total = int(match.group(3))\n                rubric_scores.append((rubric_text, score, total))\n\n    explanations = []\n    if explanation_section:\n        lines = explanation_section.group(1).strip().split(\"\\n\")\n        explanations = [line.strip() for line in lines if line.strip()]\n\n    total_score = None\n    if final_score:\n        total_score = (int(final_score.group(1)), int(final_score.group(2)))\n\n    return rubric_scores, explanations, total_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T09:53:53.106765Z","iopub.execute_input":"2025-05-03T09:53:53.106972Z","iopub.status.idle":"2025-05-03T09:53:53.130244Z","shell.execute_reply.started":"2025-05-03T09:53:53.106956Z","shell.execute_reply":"2025-05-03T09:53:53.129502Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Batchwise Parsing","metadata":{}},{"cell_type":"code","source":"def parse_batch_evaluations(responses: list[str]):\n    \"\"\"\n    Processes a list of model responses, extracting:\n    - Rubric-wise evaluations (text + marks)\n    - Explanations\n    - Final scores\n    Returns a list of dicts, one per response.\n    \"\"\"\n    results = []\n\n    for idx, response in enumerate(responses):\n        rubric_scores, explanations, total_score = parse_evaluation_response(response)\n\n        entry = {\n            \"response_index\": idx,\n            \"rubric_scores\": rubric_scores,       # List of (rubric_text, score, total)\n            \"explanations\": explanations,         # List of explanation strings\n            \"final_score\": total_score            # Tuple (score, total) or None\n        }\n\n        results.append(entry)\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T09:53:53.131091Z","iopub.execute_input":"2025-05-03T09:53:53.131377Z","iopub.status.idle":"2025-05-03T09:53:53.152964Z","shell.execute_reply.started":"2025-05-03T09:53:53.131354Z","shell.execute_reply":"2025-05-03T09:53:53.152344Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Helper function to make messages for LLM","metadata":{}},{"cell_type":"code","source":"def make_messages(question: str, answer: str, rubric: str) -> list[dict]:\n    return [\n        {\"role\": \"system\", \"content\": SYS_PROMPT},\n        {\"role\": \"user\", \"content\": f\"\"\"QUESTION:\n{question}\n\nSTUDENT ANSWER:\n{answer}\n\nRUBRIC:\n{rubric}\n\"\"\"}\n    ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T09:53:53.153873Z","iopub.execute_input":"2025-05-03T09:53:53.154301Z","iopub.status.idle":"2025-05-03T09:53:53.174737Z","shell.execute_reply.started":"2025-05-03T09:53:53.154267Z","shell.execute_reply":"2025-05-03T09:53:53.173994Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Function for Majority Voting","metadata":{}},{"cell_type":"code","source":"def majority_vote_with_explanations(parsed_batch):\n    \"\"\"\n    Takes parsed batch outputs and returns majority-voted rubric scores with explanations.\n\n    Returns:\n    - List of tuples: (rubric_text, voted_score, total, explanation)\n    \"\"\"\n    rubric_scores = defaultdict(list)  # i -> [(score, total)]\n    rubric_explanations = defaultdict(list)  # i -> [explanation]\n    rubric_texts = []\n\n    for entry in parsed_batch:\n        for i, (rubric_text, score, total) in enumerate(entry['rubric_scores']):\n            rubric_scores[i].append((score, total))\n            rubric_explanations[i].append(entry['explanations'][i])\n            if len(rubric_texts) <= i:\n                rubric_texts.append(rubric_text)\n\n    results = []\n    for i in range(len(rubric_scores)):\n        # Majority vote on score\n        score_counter = Counter(rubric_scores[i])Screenshot from 2025-05-03 17-05-41\n        (voted_score, voted_total), _ = score_counter.most_common(1)[0]\n\n        # Most common explanation\n        explanation_counter = Counter(rubric_explanations[i])\n        voted_explanation, _ = explanation_counter.most_common(1)[0]\n\n        results.append((rubric_texts[i], voted_score, voted_total, voted_explanation))\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T09:53:53.175604Z","iopub.execute_input":"2025-05-03T09:53:53.175814Z","iopub.status.idle":"2025-05-03T09:53:53.199335Z","shell.execute_reply.started":"2025-05-03T09:53:53.175799Z","shell.execute_reply":"2025-05-03T09:53:53.198506Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## For testing Individually","metadata":{}},{"cell_type":"code","source":"question = \"A car initially at rest, achieved a speed of 60 km/h in a minute. Calculate the accelaration of the car\"\nanswer = \"\"\"Given u=0m/s,t=60s\nv=60/3.6=16.67m/s\na=0.278ms^-2\n\"\"\"\nrubric = \"\"\"1. Identifies the given informations correctly (3 points)\n2. Mentions the formula for accelaration explicitely (2 points)\n3. Uses the correct formula for accelaration (3 points)\n4. Calculates the correct accelaration(Might be in m/s or km/h).(2 points)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T09:20:14.517060Z","iopub.execute_input":"2025-05-02T09:20:14.517334Z","iopub.status.idle":"2025-05-02T09:20:14.521182Z","shell.execute_reply.started":"2025-05-02T09:20:14.517315Z","shell.execute_reply":"2025-05-02T09:20:14.520385Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"question = \"\"\"\n0 থেকে π পর্যন্ত y=sinx দ্বারা আবদ্ধ ক্ষেত্রফল কত?\n\"\"\"\nanswer = \"\"\"\nধরি, \n\\[\nA = \\int_{0}^{\\pi} \\sin x \\, dx\n\\]\n\nআমরা জানি,\n\\[\n\\int \\sin x \\, dx = -\\cos x + C\n\\]\n\nঅতএব,\n\\[\nA = \\left[-\\cos x\\right]_{0}^{\\pi}\n= \\left(-\\cos \\pi\\right) - \\left(-\\cos 0\\right)\n\\]\n\n\\[\n= -(-1) - (-1)\n= 1 + 1 = 2\n\\]\n\nসুতরাং,\n\\[\n\\boxed{ \\text{ক্ষেত্রফল} = 2 \\text{ একক} }\n\\]\n\"\"\"\n\nrubric = \"\"\"\n1. ক্ষেত্রফলের সাথে সম্পর্কিত নির্দিষ্ট ইন্টিগ্রাল চিহ্নিত করে। (4 points)\n2. ক্ষেত্রফল ইন্টিগ্রেট করার জন্য সঠিক সূত্র ব্যবহার করে। (3 points)\n3. সঠিক ক্ষেত্রফল গণনা করে। (3 points)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T10:12:15.876621Z","iopub.execute_input":"2025-05-03T10:12:15.877217Z","iopub.status.idle":"2025-05-03T10:12:15.881429Z","shell.execute_reply.started":"2025-05-03T10:12:15.877193Z","shell.execute_reply":"2025-05-03T10:12:15.880774Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# question = \"Find the derivative of f(x) = x³ + 3x² + 1.\"\n# answer = \"f'(x) = 3x² + 6x.\"\n# rubric = \"\"\"1. States the general power rule (d/dx[xⁿ]=n·xⁿ⁻¹) (2 points)\n# 2. Applies the power rule correctly to x³ (2 points)\n# 3. Applies the power rule correctly to 3x² (2 points)\n# 4. Simplifies and combines like terms properly (2 points)\"\"\"\n\nmessages_batch = [make_messages(question, answer, rubric)] * 10  # for 5 voting samplesScreenshot from 2025-05-03 17-05-41\n\nresponses = llm_engine(messages_batch)\nparsed_results = parse_batch_evaluations(responses)\n# majority_scores,majority_explanations,totals = majority_scores_per_rubric(parsed_results)\nresults = majority_vote_with_explanations(parsed_results)\ntotal_mark = 0\n\n# for result in parsed_results:\n#     print(f\"\\n🔎 Response #{result['response_index'] + 1}\")\n\n#     marks_got = 0\n#     total_marks = 0\n#     for i, ((rubric, score, total), explanation) in enumerate(zip(result[\"rubric_scores\"], result[\"explanations\"]), 1):\n#         marks_got += score\n#         total_marks += total\n#         print(f\"{i}. {rubric} => Score: {score}/{total}\")\n#         print(f\"   Explanation: {explanation}\")\n    \n#     if result[\"final_score\"]:\n#         print(f\"\\n✅ Final Score: {result['final_score'][0]}/{result['final_score'][1]}\")\n#     total_mark = total_marks\n#     print(f\"\\nSummed Final Score: {marks_got}/{total_marks}\\n\")\n\nmajority_scores = []\nfor rubric_text, score, total, explanation in results:\n    majority_scores.append(score)\n    total_mark += total\n    print(f\"{rubric_text}. Score => {score}/{total}\")\n    # print(f\"Explanation: {explanation}\")\n    print()\n\n\nprint(f\"\\nFinal Score according to majority voting: {sum(majority_scores)}/{total_mark}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T10:01:38.382082Z","iopub.execute_input":"2025-05-03T10:01:38.382688Z","iopub.status.idle":"2025-05-03T10:02:05.179895Z","shell.execute_reply.started":"2025-05-03T10:01:38.382665Z","shell.execute_reply":"2025-05-03T10:02:05.179245Z"}},"outputs":[{"name":"stdout","text":"1. The student correctly identifies the integral for the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\).. Score => 4/4\n\n2. The student uses the correct formula for integrating \\(\\sin x\\), which is \\(\\int \\sin x \\, dx = -\\cos x + C\\).. Score => 3/3\n\n3. The student correctly calculates the area under the curve, which is 2 square units.. Score => 3/3\n\n\nFinal Score according to majority voting: 10/10\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### The following cell prints the raw responses","metadata":{}},{"cell_type":"code","source":"# question = \"Find the derivative of f(x) = x³ + 3x² + 1.\"\n# answer = \"f'(x) = 3x² + 6x.\"\n# rubric = \"\"\"1. States the general power rule (d/dx[xⁿ]=n·xⁿ⁻¹) (2 points)\n# 2. Applies the power rule correctly to x³ (2 points)\n# 3. Applies the power rule correctly to 3x² (2 points)\n# 4. Writes the final result properly(no need to write 0 in the final result) (2 points)\"\"\"\n\nmessages_batch = [make_messages(question, answer, rubric)] * 5  # for 5 voting samples\n\nresponses = llm_engine(messages_batch)\n\nfor response in responses:\n    print(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T10:02:47.194048Z","iopub.execute_input":"2025-05-03T10:02:47.194932Z","iopub.status.idle":"2025-05-03T10:02:59.173557Z","shell.execute_reply.started":"2025-05-03T10:02:47.194905Z","shell.execute_reply":"2025-05-03T10:02:59.172881Z"},"_kg_hide-output":false},"outputs":[{"name":"stdout","text":"Evaluation:\n1. The student correctly identifies the integral for the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\). <marks>4/4</marks>\n2. The student uses the correct formula for integrating \\( \\sin x \\), which is \\( \\int \\sin x \\, dx = -\\cos x + C \\). <marks>3/3</marks>\n3. The student calculates the area correctly, resulting in an area of 2 square units. <marks>3/3</marks>\n\nExplanation:\n1. The student correctly sets up the integral \\( A = \\int_{0}^{\\pi} \\sin x \\, dx \\), which is the integral for the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\).\n2. The student uses the correct antiderivative \\( \\int \\sin x \\, dx = -\\cos x + C \\) to evaluate the definite integral.\n3. The student evaluates the definite integral correctly, resulting in \\( A = 2 \\) square units.\n\nFinal Score: <score>10/10</score>\nEvaluation:\n1. The student correctly identifies the integral for the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\). <marks>4/4</marks>\n2. The student uses the correct formula for integrating \\( \\sin x \\), which is \\( \\int \\sin x \\, dx = -\\cos x + C \\). <marks>3/3</marks>\n3. The student correctly calculates the definite integral and finds the area to be 2 square units. <marks>3/3</marks>\n\nExplanation:\n1. The student correctly sets up the integral \\( A = \\int_{0}^{\\pi} \\sin x \\, dx \\), which is the integral for the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\).\n2. The student uses the correct antiderivative \\( \\int \\sin x \\, dx = -\\cos x + C \\) to evaluate the definite integral.\n3. The student correctly evaluates the definite integral and finds the area to be 2 square units, which is accurate.\n\nFinal Score: <score>10/10</score>\nEvaluation:\n1. The student correctly identifies the integral for the area under the curve \\( y = \\sin x \\) from 0 to \\(\\pi\\). <marks>4/4</marks>\n2. The student uses the correct formula for integrating \\(\\sin x\\), which is \\(\\int \\sin x \\, dx = -\\cos x + C\\). <marks>3/3</marks>\n3. The student calculates the area correctly, resulting in an area of 2 square units. <marks>3/3</marks>\n\nExplanation:\n1. The student correctly sets up the integral \\( A = \\int_{0}^{\\pi} \\sin x \\, dx \\) to find the area under the curve.\n2. The student applies the correct antiderivative \\(\\int \\sin x \\, dx = -\\cos x + C\\) to evaluate the definite integral.\n3. The student evaluates the definite integral correctly, resulting in the area \\( A = 2 \\).\n\nFinal Score: <score>10/10</score>\nEvaluation:\n1. The student correctly identifies the integral for the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\). <marks>4/4</marks>\n2. The student uses the correct formula for integrating \\(\\sin x\\), which is \\(\\int \\sin x \\, dx = -\\cos x + C\\). <marks>3/3</marks>\n3. The student calculates the area correctly as 2 square units. <marks>3/3</marks>\n\nExplanation:\n1. The student correctly sets up the integral \\(\\int_{0}^{\\pi} \\sin x \\, dx\\) to find the area under the curve.\n2. The student correctly applies the integral formula \\(\\int \\sin x \\, dx = -\\cos x + C\\) and evaluates the definite integral from 0 to \\(\\pi\\).\n3. The student correctly evaluates the definite integral and finds the area to be 2 square units.\n\nFinal Score: <score>10/10</score>\nEvaluation:\n1. The student correctly identifies the integral for the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\). <marks>4/4</marks>\n2. The student uses the correct formula for integrating \\( \\sin x \\), which is \\( \\int \\sin x \\, dx = -\\cos x + C \\). <marks>3/3</marks>\n3. The student calculates the area correctly, resulting in an area of 2 square units. <marks>3/3</marks>\n\nExplanation:\n1. The integral \\( \\int_{0}^{\\pi} \\sin x \\, dx \\) is correctly identified as the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\).\n2. The student uses the correct antiderivative \\( -\\cos x \\) for \\( \\sin x \\).\n3. The student evaluates the definite integral correctly, resulting in the area \\( 2 \\) square units.\n\nFinal Score: <score>10/10</score>\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Evaluating Multiple questions at once!","metadata":{}},{"cell_type":"code","source":"questions_answers_list = [\n    {\n        \"question\" : \"\"\"\n        0 থেকে π পর্যন্ত y=sinx দ্বারা আবদ্ধ ক্ষেত্রফল কত?\n        \"\"\",\n        \"answer\" : \"\"\"\n        ধরি, \n        \\[\n        A = \\int_{0}^{\\pi} \\sin x \\, dx\n        \\]\n        \n        আমরা জানি,\n        \\[\n        \\int \\sin x \\, dx = -\\cos x + C\n        \\]\n        \n        অতএব,\n        \\[\n        A = \\left[-\\cos x\\right]_{0}^{\\pi}\n        = \\left(-\\cos \\pi\\right) - \\left(-\\cos 0\\right)\n        \\]\n    \n        \\[\n        = -(-1) - (-1)\n        = 1 + 1 = 2\n        \\]\n        \n        সুতরাং,\n        \\[\n        \\boxed{ \\text{ক্ষেত্রফল} = 2 \\text{ একক} }\n        \\]\n        \"\"\",\n    \n        \"rubric\" : \"\"\"\n        1. ক্ষেত্রফলের সাথে সম্পর্কিত নির্দিষ্ট ইন্টিগ্রাল চিহ্নিত করে। (4 points)\n        2. ক্ষেত্রফল ইন্টিগ্রেট করার জন্য সঠিক সূত্র ব্যবহার করে। (3 points)\n        3. সঠিক ক্ষেত্রফল গণনা করে। (3 points)\n        \"\"\"\n    },\n    {\n        \"question\" : \"A car initially at rest, achieved a speed of 60 km/h in a minute. Calculate the accelaration of the car\",\n        \"answer\" : \"\"\"Given u=0m/s,t=60s\n        v=60/3.6=16.67m/s\n        a=0.278ms^-2\n        \"\"\",\n        \"rubric\" : \"\"\"1. Identifies the given informations correctly (3 points)\n        2. Mentions the formula for accelaration explicitely (2 points)\n        3. Uses the correct formula for accelaration (3 points)\n        4. Calculates the correct accelaration(Might be in m/s or km/h).(2 points)\n        \"\"\"\n    },\n    {\n        \"question\" : \"\"\"The time period of a simple pendulum in earth is 2 seconds. What will be its time period\n        in space?\n        \"\"\",\n        \"answer\" : \"The time period will be unchanged. It will still be 2 seconds\",\n        \"rubric\" : \"1. Provides the correct answer (2 points)\"\n    }\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:00:52.903998Z","iopub.execute_input":"2025-05-03T11:00:52.904667Z","iopub.status.idle":"2025-05-03T11:00:52.910199Z","shell.execute_reply.started":"2025-05-03T11:00:52.904640Z","shell.execute_reply":"2025-05-03T11:00:52.909235Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"messages_batches = []\nfor qa in questions_answers_list: # This list is a list of dictionaries(for now)\n    question, answer, rubric = qa[\"question\"], qa[\"answer\"], qa[\"rubric\"]\n    single_message = make_messages(question, answer, rubric)\n    batch = [single_message] * 5  # 5 copies per question\n    messages_batches.extend(batch)  # flatten for vllm batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:01:37.077795Z","iopub.execute_input":"2025-05-03T11:01:37.078087Z","iopub.status.idle":"2025-05-03T11:01:37.082645Z","shell.execute_reply.started":"2025-05-03T11:01:37.078066Z","shell.execute_reply":"2025-05-03T11:01:37.081977Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Function to run LLM for batches","metadata":{}},{"cell_type":"code","source":"def chunked(iterable, size):\n    \"\"\"Yield successive chunks from iterable.\"\"\"\n    for i in range(0, len(iterable), size):\n        yield iterable[i:i + size]\n\ndef run_llm_in_batches(messages_batches: List[list], batch_size: int = 48, group_size: int = 5) -> List[List[str]]:\n    \"\"\"\n    Runs the llm_engine in fixed-size batches and groups responses for majority voting.\n\n    Args:\n        messages_batches (List[list]): List of chat-format messages (prompt per instance).\n        batch_size (int): Number of messages to send per call to llm_engine.\n        group_size (int): Number of completions per logical instance (for majority voting).\n\n    Returns:\n        grouped_responses (List[List[str]]): Responses grouped per question.\n    \"\"\"\n    all_responses = []\n\n    for batch in chunked(messages_batches, batch_size):\n        responses = llm_engine(batch)\n        all_responses.extend(responses)\n\n    # Group responses (e.g., for 5 votes per question)\n    grouped_responses = [all_responses[i:i + group_size] for i in range(0, len(all_responses), group_size)]\n\n    return grouped_responses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:01:43.042143Z","iopub.execute_input":"2025-05-03T11:01:43.042913Z","iopub.status.idle":"2025-05-03T11:01:43.049105Z","shell.execute_reply.started":"2025-05-03T11:01:43.042886Z","shell.execute_reply":"2025-05-03T11:01:43.048322Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Function for Majority voting in Grouped Responses","metadata":{}},{"cell_type":"code","source":"def aggregate_majority_votes(grouped_responses):\n    \"\"\"\n    Parses and performs majority voting with explanations on grouped LLM responses.\n\n    Args:\n        grouped_responses (List[List[str]]): Responses grouped per question.\n\n    Returns:\n        List[List[Tuple[str, int, int, str]]]: \n            For each question:\n                A list of tuples (rubric_text, majority_score, total, explanation).\n    \"\"\"\n    final_results = []\n\n    for group in grouped_responses:\n        parsed = parse_batch_evaluations(group)\n        rubric_scores = majority_vote_with_explanations(parsed)\n        final_results.append(rubric_scores)\n\n    return final_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:02:05.418791Z","iopub.execute_input":"2025-05-03T11:02:05.419070Z","iopub.status.idle":"2025-05-03T11:02:05.423585Z","shell.execute_reply.started":"2025-05-03T11:02:05.419052Z","shell.execute_reply":"2025-05-03T11:02:05.422888Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Helper function to print the final Evaluation","metadata":{}},{"cell_type":"code","source":"def print_majority_vote_results(final_results, questions=None):\n    \"\"\"\n    Nicely prints rubric-wise majority scores and explanations.\n\n    Args:\n        final_results: List of lists of tuples (rubric_text, score, total, explanation)\n        questions: Optional list of question texts for headers\n    \"\"\"\n    for i, rubric_scores in enumerate(final_results):\n        if questions:\n            print(f\"\\n📌 Question {i+1}: {questions[i]}\")\n        else:\n            print(f\"\\n📌 Question {i+1}:\")\n\n        total_score = 0\n        total_possible = 0\n\n        for j, (rubric, score, total, explanation) in enumerate(rubric_scores):\n            print(f\"\\n🧾 Rubric {j+1}: {rubric}\")\n            print(f\"✅ Score: {score}/{total}\")\n            print(f\"🗒️ Explanation: {explanation}\")\n            total_score += score\n            total_possible += total\n\n        print(f\"\\n🏁 Final Score: {total_score}/{total_possible}\")\n        print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:02:07.415718Z","iopub.execute_input":"2025-05-03T11:02:07.416408Z","iopub.status.idle":"2025-05-03T11:02:07.421835Z","shell.execute_reply.started":"2025-05-03T11:02:07.416384Z","shell.execute_reply":"2025-05-03T11:02:07.421271Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"grouped_outputs = run_llm_in_batches(messages_batches, batch_size=48, group_size=5)\nfinal_results = aggregate_majority_votes(grouped_outputs)\nprint_majority_vote_results(final_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:02:14.421822Z","iopub.execute_input":"2025-05-03T11:02:14.422108Z","iopub.status.idle":"2025-05-03T11:02:32.053174Z","shell.execute_reply.started":"2025-05-03T11:02:14.422090Z","shell.execute_reply":"2025-05-03T11:02:32.052526Z"}},"outputs":[{"name":"stdout","text":"\n📌 Question 1:\n\n🧾 Rubric 1: 1. The student correctly identifies the integral for the area under the curve \\( y = \\sin x \\) from \\( 0 \\) to \\( \\pi \\).\n✅ Score: 4/4\n🗒️ Explanation: 1. The student correctly sets up the integral \\( A = \\int_{0}^{\\pi} \\sin x \\, dx \\) to find the area under the curve.\n\n🧾 Rubric 2: 2. The student uses the correct formula for integrating \\( \\sin x \\), which is \\( \\int \\sin x \\, dx = -\\cos x + C \\).\n✅ Score: 3/3\n🗒️ Explanation: 2. The student correctly uses the antiderivative \\( \\int \\sin x \\, dx = -\\cos x + C \\) to evaluate the definite integral.\n\n🧾 Rubric 3: 3. The student correctly calculates the definite integral and finds the area to be 2 square units.\n✅ Score: 3/3\n🗒️ Explanation: 3. The student correctly evaluates the definite integral and finds the area to be 2 square units.\n\n🏁 Final Score: 10/10\n--------------------------------------------------\n\n📌 Question 2:\n\n🧾 Rubric 1: 1. The student correctly identifies the given information: initial velocity (u=0 m/s), time (t=60 s), and final velocity (v=16.67 m/s).\n✅ Score: 3/3\n🗒️ Explanation: 1. The student correctly identifies the initial velocity (u=0 m/s), time (t=60 s), and final velocity (v=16.67 m/s).\n\n🧾 Rubric 2: 2. The student does not explicitly mention the formula for acceleration.\n✅ Score: 0/2\n🗒️ Explanation: 2. The formula for acceleration (a = (v - u) / t) is not explicitly mentioned.\n\n🧾 Rubric 3: 3. The student uses the correct formula for acceleration, a = (v - u) / t.\n✅ Score: 3/3\n🗒️ Explanation: 3. The formula a = (v - u) / t is used correctly.\n\n🧾 Rubric 4: 4. The student calculates the correct acceleration: a = (16.67 m/s - 0 m/s) / 60 s = 0.278 m/s².\n✅ Score: 2/2\n🗒️ Explanation: 4. The acceleration is calculated correctly as 0.278 m/s².\n\n🏁 Final Score: 8/10\n--------------------------------------------------\n\n📌 Question 3:\n\n🧾 Rubric 1: 1. The student did not provide the correct answer.\n✅ Score: 0/2\n🗒️ Explanation: 1. The time period of a simple pendulum is given by the formula \\( T = 2\\pi \\sqrt{\\frac{L}{g}} \\), where \\( L \\) is the length of the pendulum and \\( g \\) is the acceleration due to gravity. In space, the acceleration due to gravity \\( g \\) is significantly reduced or zero, which means the time period \\( T \\) would increase or become undefined (since the pendulum would not swing if there is no gravity).\n\n🏁 Final Score: 0/2\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}